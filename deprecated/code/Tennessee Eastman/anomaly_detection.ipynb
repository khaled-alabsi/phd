{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed2330e",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "TARGET_VARIABLE_COLUMN_NAME = \"faultNumber\"\n",
    "SIMULATION_RUN_COLUMN_NAME = \"simulationRun\"\n",
    "COLUMNS_TO_REMOVE = [\"faultNumber\",\"simulationRun\", \"sample\"]\n",
    "\n",
    "\n",
    "\n",
    "fault_free_training_dict = pyreadr.read_r(\"data/TEP_FaultFree_Training.RData\")\n",
    "fault_free_testing_dict = pyreadr.read_r(\"data/TEP_FaultFree_Testing.RData\")\n",
    "\n",
    "faulty_training_dict = pyreadr.read_r(\"data/TEP_Faulty_Training.RData\")\n",
    "faulty_testing_dict = pyreadr.read_r(\"data/TEP_Faulty_Testing.RData\")\n",
    "\n",
    "DF_FF_TRAINING_RAW = fault_free_training_dict[\"fault_free_training\"]\n",
    "DF_FF_TEST_RAW = fault_free_testing_dict[\"fault_free_testing\"]\n",
    "\n",
    "DF_F_TRAINING_RAW = faulty_training_dict[\"faulty_training\"]\n",
    "DF_F_TEST_RAW = faulty_testing_dict[\"faulty_testing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a8428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-control X training data\n",
    "scaler_incontrol = StandardScaler()\n",
    "X_INCONTROL_TRAIN_FULL_DF = DF_FF_TRAINING_RAW.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "scaler_incontrol.fit(X_INCONTROL_TRAIN_FULL_DF)\n",
    "X_INCONTROL_TRAIN_FULL_SCALED = scaler_incontrol.transform(X_INCONTROL_TRAIN_FULL_DF)\n",
    "print(\"In-control training data shape:\", X_INCONTROL_TRAIN_FULL_SCALED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff341f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_run = 1\n",
    "fault_number = 2\n",
    "\n",
    "DF_FF_TRAINING = DF_FF_TRAINING_RAW.query(\"simulationRun == @simulation_run\")\n",
    "DF_FF_TEST = DF_FF_TEST_RAW.query(\"simulationRun == @simulation_run\")\n",
    "\n",
    "DF_F_TRAINING = DF_F_TRAINING_RAW.query(\"faultNumber == @fault_number and simulationRun == @simulation_run\")\n",
    "DF_F_TEST = DF_F_TEST_RAW.query(\"faultNumber == @fault_number and simulationRun == @simulation_run\")\n",
    "\n",
    "\n",
    "# In-control test data\n",
    "#scaler_incontrol = StandardScaler()\n",
    "X_INCONTROL_TRAIN_PLAY_DF = DF_FF_TRAINING.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "X_INCONTROL_TEST_PLAY_DF = DF_FF_TEST.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "scaler_incontrol.fit(X_INCONTROL_TRAIN_PLAY_DF)\n",
    "X_INCONTROL_TRAIN_PLAY_SCALED = scaler_incontrol.transform(X_INCONTROL_TRAIN_PLAY_DF)\n",
    "X_INCONTROL_TEST_PLAY_SCALED = scaler_incontrol.transform(X_INCONTROL_TEST_PLAY_DF)\n",
    "\n",
    "# Out-of-control test data\n",
    "X_OUT_OF_CONTROL_TEST_PLAY_DF = DF_F_TEST.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "X_OUT_OF_CONTROL_TRAIN_PLAY_DF = DF_F_TRAINING.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "X_OUT_OF_CONTROL_TEST_PLAY_SCALED = scaler_incontrol.transform(X_OUT_OF_CONTROL_TEST_PLAY_DF)\n",
    "X_OUT_OF_CONTROL_TRAIN_PLAY_SCALED = scaler_incontrol.transform(X_OUT_OF_CONTROL_TRAIN_PLAY_DF)\n",
    "\n",
    "print(\"In-control training data shape:\", X_INCONTROL_TRAIN_PLAY_SCALED.shape)\n",
    "print(\"In-control test data shape:\", X_INCONTROL_TEST_PLAY_SCALED.shape)\n",
    "print(\"Out-of-control training data shape:\", X_OUT_OF_CONTROL_TRAIN_PLAY_SCALED.shape)\n",
    "print(\"Out-of-control test data shape:\", X_OUT_OF_CONTROL_TEST_PLAY_SCALED.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889472ff",
   "metadata": {},
   "source": [
    "## MCUSUM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01898388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCUSUM (MULTIVARIATE CUMULATIVE SUM) IMPLEMENTATION\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "\n",
    "class MCUSUMDetector:\n",
    "\n",
    "    def __init__(self, k = 0.5, h = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            k: Reference value (sensitivity parameter)\n",
    "            h: Control limit (threshold for detection)\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.h = h\n",
    "        self.mu_0 = None\n",
    "        self.sigma = None\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def fit(self, X_incontrol: NDArray[np.float64], verbose: bool = False) -> 'MCUSUMDetector':\n",
    "        \"\"\"\n",
    "        Fit MCUSUM parameters using in-control training data.\n",
    "        \n",
    "        Args:\n",
    "            X_incontrol: In-control (normal) training data\n",
    "            \n",
    "        Returns:\n",
    "            Self for method chaining\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(f\"ðŸ”§ **Fitting MCUSUM Parameters**\")\n",
    "\n",
    "        self.mu_0, self.sigma = self._estimate_incontrol_parameters(X_incontrol)\n",
    "        \n",
    "        if self.h is None:\n",
    "            self.h = self._estimate_control_limit(X_incontrol)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"   Mean vector shape: {self.mu_0.shape}\")\n",
    "            print(f\"   Covariance matrix shape: {self.sigma.shape}\")\n",
    "            print(f\"   Reference value k: {self.k:.4f}\")\n",
    "            print(f\"   Control limit h: {self.h:.4f}\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test: NDArray[np.float64]):\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"MCUSUM detector must be fitted before prediction\")\n",
    "\n",
    "        statistics = self._compute_mcusum_scores(X_test, self.mu_0, self.sigma, self.k)\n",
    "        flags = statistics > self.h\n",
    "        \n",
    "        return statistics, flags\n",
    "    \n",
    "    @staticmethod\n",
    "    def _estimate_incontrol_parameters(X_incontrol: NDArray[np.float64]) :\n",
    "        \"\"\"\n",
    "        Estimate mean vector and covariance matrix from in-control data.\n",
    "        \n",
    "        Args:\n",
    "            X_incontrol: In-control training data\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (mean vector, covariance matrix)\n",
    "        \"\"\"\n",
    "        mu_0 = np.mean(X_incontrol, axis=0)\n",
    "        sigma = np.cov(X_incontrol, rowvar=False, bias=False)\n",
    "        \n",
    "        # Ensure positive definite covariance matrix\n",
    "        min_eigenval = np.min(np.linalg.eigvals(sigma))\n",
    "        if min_eigenval <= 0:\n",
    "            print(f\"âš ï¸  Warning: Adding regularization to covariance matrix (min eigenvalue: {min_eigenval:.2e})\")\n",
    "            sigma += np.eye(sigma.shape[0]) * abs(min_eigenval) * 1.01\n",
    "        \n",
    "        return mu_0, sigma\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compute_mcusum_scores(X_test: NDArray[np.float64],\n",
    "                              mu_0,\n",
    "                              sigma,\n",
    "                              k):\n",
    "        \"\"\"\n",
    "        Compute MCUSUM statistics for test data.\n",
    "        \n",
    "        Args:\n",
    "            X_test: Test data\n",
    "            mu_0: In-control mean vector\n",
    "            sigma: In-control covariance matrix\n",
    "            k: Reference value\n",
    "            \n",
    "        Returns:\n",
    "            MCUSUM statistics for each sample\n",
    "        \"\"\"\n",
    "        X_test = np.asarray(X_test)\n",
    "        mu_0 = np.asarray(mu_0)\n",
    "        sigma = np.asarray(sigma)\n",
    "        \n",
    "        n_samples, n_features = X_test.shape\n",
    "        \n",
    "        # Compute whitening transformation: Î£^{-1/2}\n",
    "        try:\n",
    "            eigvals, eigvecs = np.linalg.eigh(sigma)\n",
    "            eigvals_inv_sqrt = np.diag(1.0 / np.sqrt(np.maximum(eigvals, 1e-12)))\n",
    "            sigma_inv_sqrt = eigvecs @ eigvals_inv_sqrt @ eigvecs.T\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"âš ï¸  Warning: Using pseudo-inverse for covariance matrix\")\n",
    "            sigma_inv_sqrt = np.linalg.pinv(sigma)\n",
    "        \n",
    "        # Whiten the data\n",
    "        Z = (X_test - mu_0) @ sigma_inv_sqrt.T\n",
    "        \n",
    "        # MCUSUM recursion\n",
    "        S_t = np.zeros(n_features)\n",
    "        T = np.zeros(n_samples)\n",
    "        \n",
    "        for t in range(n_samples):\n",
    "            V_t = S_t + Z[t]\n",
    "            norm_V_t = np.linalg.norm(V_t)\n",
    "            \n",
    "            if norm_V_t <= k:\n",
    "                S_t = np.zeros(n_features)\n",
    "            else:\n",
    "                shrinkage = 1.0 - k / norm_V_t\n",
    "                S_t = V_t * shrinkage\n",
    "            \n",
    "            T[t] = np.linalg.norm(S_t)\n",
    "        \n",
    "        return T\n",
    "    \n",
    "    def _estimate_control_limit(self, X_incontrol: NDArray[np.float64],\n",
    "                              n_simulations: int = 500,\n",
    "                              percentile: float = 99.0,\n",
    "                              verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Estimate control limit using Monte Carlo simulation.\n",
    "        \n",
    "        Args:\n",
    "            X_incontrol: In-control training data\n",
    "            n_simulations: Number of Monte Carlo simulations\n",
    "            percentile: Percentile for control limit\n",
    "            \n",
    "        Returns:\n",
    "            Estimated control limit\n",
    "        \"\"\"\n",
    "\n",
    "        max_T_values = []\n",
    "        sample_size = min(300, X_incontrol.shape[0])\n",
    "        \n",
    "        for i in range(n_simulations):\n",
    "            # Bootstrap sample from in-control data\n",
    "            indices = np.random.choice(X_incontrol.shape[0], size=sample_size, replace=True)\n",
    "            sample = X_incontrol[indices]\n",
    "            \n",
    "            # Compute MCUSUM statistics\n",
    "            T = self._compute_mcusum_scores(sample, self.mu_0, self.sigma, self.k)\n",
    "            max_T_values.append(np.max(T))\n",
    "        \n",
    "        h = np.percentile(max_T_values, percentile)\n",
    "        if verbose:\n",
    "            print(f\"   Control limit (h) estimated at {percentile}th percentile: {h:.4f}\")\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_reference_value_k(delta,\n",
    "                                 sigma):\n",
    "        \"\"\"\n",
    "        Compute optimal reference value k = 0.5 * ||Î£^{-1/2} Î´||\n",
    "        \n",
    "        Args:\n",
    "            delta: Expected shift vector\n",
    "            sigma: In-control covariance matrix\n",
    "            \n",
    "        Returns:\n",
    "            Optimal reference value\n",
    "        \"\"\"\n",
    "        # Whitening matrix computation\n",
    "        eigvals, eigvecs = np.linalg.eigh(sigma)\n",
    "        eigvals_inv_sqrt = np.diag(1.0 / np.sqrt(np.maximum(eigvals, 1e-12)))\n",
    "        sigma_inv_sqrt = eigvecs @ eigvals_inv_sqrt @ eigvecs.T\n",
    "        \n",
    "        # Transform delta and compute norm\n",
    "        whitened_delta = sigma_inv_sqrt @ delta\n",
    "        k = 0.5 * np.linalg.norm(whitened_delta)\n",
    "        \n",
    "        return k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a538243",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcusum = None  # Global MCUSUM instance to be initialized later\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "def plot_mcusum_diagnostics(\n",
    "    statistics_normal: NDArray[np.float64],\n",
    "    statistics_anomaly: Optional[NDArray[np.float64]] = None,\n",
    "    h: float | None = 0.0,\n",
    "    title_suffix: str = \"\",\n",
    "    use_log: bool = True,\n",
    "    diff_threshold: float = 1e-3\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create MCUSUM diagnostic plots with markers for differences and control limit crossings.\n",
    "    \"\"\"\n",
    "    rows = 3 if statistics_anomaly is not None else 1\n",
    "    fig, axs = plt.subplots(rows, 2, figsize=(15, 5 * rows))\n",
    "    if rows == 1:\n",
    "        axs = np.array([axs])\n",
    "\n",
    "    # Helper to set y-axis log if requested\n",
    "    def maybe_log(ax):\n",
    "        if use_log:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "    # Normal histogram\n",
    "    axs[0, 0].hist(statistics_normal, bins=50, alpha=0.7, color='blue', density=True)\n",
    "    axs[0, 0].axvline(h, color='red', linestyle='--', linewidth=2, label=f'Control Limit (h={h:.2f})')\n",
    "    maybe_log(axs[0, 0])\n",
    "    axs[0, 0].set_xlabel(\"MCUSUM Statistic\")\n",
    "    axs[0, 0].set_ylabel(\"Density\")\n",
    "    axs[0, 0].set_title(f\"Normal Data Histogram {title_suffix}\")\n",
    "    axs[0, 0].legend()\n",
    "    axs[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Normal time series\n",
    "    axs[0, 1].plot(statistics_normal, color='blue', alpha=0.7, label=\"Normal Data\")\n",
    "    axs[0, 1].axhline(h, color='red', linestyle='--', linewidth=2, label=f'Control Limit (h={h:.2f})')\n",
    "    maybe_log(axs[0, 1])\n",
    "    axs[0, 1].set_xlabel(\"Sample Index\")\n",
    "    axs[0, 1].set_ylabel(\"MCUSUM Statistic\")\n",
    "    axs[0, 1].set_title(f\"Normal Data Over Time {title_suffix}\")\n",
    "    axs[0, 1].legend()\n",
    "    axs[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    if statistics_anomaly is not None:\n",
    "        # Anomaly histogram\n",
    "        axs[1, 0].hist(statistics_anomaly, bins=50, alpha=0.7, color='red', density=True)\n",
    "        axs[1, 0].axvline(h, color='red', linestyle='--', linewidth=2, label=f'Control Limit (h={h:.2f})')\n",
    "        maybe_log(axs[1, 0])\n",
    "        axs[1, 0].set_xlabel(\"MCUSUM Statistic\")\n",
    "        axs[1, 0].set_ylabel(\"Density\")\n",
    "        axs[1, 0].set_title(f\"Anomaly Data Histogram {title_suffix}\")\n",
    "        axs[1, 0].legend()\n",
    "        axs[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Anomaly time series\n",
    "        axs[1, 1].plot(statistics_anomaly, color='red', alpha=0.7, label=\"Anomaly Data\")\n",
    "        axs[1, 1].axhline(h, color='red', linestyle='--', linewidth=2, label=f'Control Limit (h={h:.2f})')\n",
    "        maybe_log(axs[1, 1])\n",
    "        axs[1, 1].set_xlabel(\"Sample Index\")\n",
    "        axs[1, 1].set_ylabel(\"MCUSUM Statistic\")\n",
    "        axs[1, 1].set_title(f\"Anomaly Data Over Time {title_suffix}\")\n",
    "        axs[1, 1].legend()\n",
    "        axs[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "        # Overlay plot\n",
    "        axs[2, 0].plot(statistics_normal, color='blue', alpha=0.7, label=\"Normal Data\")\n",
    "        axs[2, 0].plot(statistics_anomaly, color='red', alpha=0.7, label=\"Anomaly Data\")\n",
    "        axs[2, 0].axhline(h, color='red', linestyle='--', linewidth=2, label=f'Control Limit (h={h:.2f})')\n",
    "        maybe_log(axs[2, 0])\n",
    "        axs[2, 0].set_xlabel(\"Sample Index\")\n",
    "        axs[2, 0].set_ylabel(\"MCUSUM Statistic\")\n",
    "        axs[2, 0].set_title(f\"Normal vs Anomaly Overlay {title_suffix}\")\n",
    "        axs[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "        # First point above threshold difference\n",
    "        diff = np.abs(statistics_normal - statistics_anomaly)\n",
    "        if np.any(diff > diff_threshold):\n",
    "            idx_diff = np.argmax(diff > diff_threshold)\n",
    "            val_norm = statistics_normal[idx_diff]\n",
    "            val_anom = statistics_anomaly[idx_diff]\n",
    "            axs[2, 0].axvline(idx_diff, color='green', linestyle='--', linewidth=2,\n",
    "                               label=f'First Diff (idx={idx_diff})')\n",
    "            # axs[2, 0].annotate(f\"{val_norm:.4f} / {val_anom:.4f}\",\n",
    "            #                     xy=(idx_diff, max(val_norm, val_anom)),\n",
    "            #                     xytext=(idx_diff + 5, max(val_norm, val_anom) * 1.05),\n",
    "            #                     arrowprops=dict(arrowstyle=\"->\", color='green'),\n",
    "            #                     color='green')\n",
    "\n",
    "        # First point above control limit\n",
    "        for series, color, label_prefix in zip([statistics_normal, statistics_anomaly],\n",
    "                                               ['purple', 'orange'],\n",
    "                                               ['Normal', 'Anomaly']):\n",
    "            if np.any(series > h):\n",
    "                idx_h = np.argmax(series > h)\n",
    "                val_h = series[idx_h]\n",
    "                axs[2, 0].axvline(idx_h, color=color, linestyle='--', linewidth=2,\n",
    "                                   label=f'{label_prefix} first above h (idx={idx_h})')\n",
    "                # axs[2, 0].annotate(f\"{val_h:.4f}\",\n",
    "                #                     xy=(idx_h, val_h),\n",
    "                #                     xytext=(idx_h + 5, val_h * 1.05),\n",
    "                #                     arrowprops=dict(arrowstyle=\"->\", color=color),\n",
    "                #                     color=color)\n",
    "\n",
    "        axs[2, 0].legend(loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "        fig.delaxes(axs[2, 1])  # remove unused subplot\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def apply_mcusum(X_INCONTROL_TEST, X_OUT_OF_CONTROL_TEST, verbose: bool = True) -> Tuple[NDArray[np.int_], NDArray[np.int_]]:\n",
    "    \n",
    "    stats_normal, flags_normal = mcusum.predict(X_INCONTROL_TEST)\n",
    "    stats_anomaly, flags_anomaly = mcusum.predict(X_OUT_OF_CONTROL_TEST)\n",
    "    \n",
    "    # Create diagnostic plots\n",
    "    if verbose:\n",
    "        plot_mcusum_diagnostics(stats_normal, stats_anomaly, mcusum.h, \"Tennessee_Eastman\") # type: ignore\n",
    "\n",
    "    # Convert boolean flags to 0 (normal) and 1 (anomaly)\n",
    "    return flags_normal.astype(int), flags_anomaly.astype(int)\n",
    "\n",
    "\n",
    "def mcusum_predict(x_scaled):\n",
    "\n",
    "    stats_normal, y_pred = mcusum.predict(x_scaled)\n",
    "\n",
    "    return y_pred.astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_INCONTROL_TRAIN_FULL_SCALED.shape[1]\n",
    "delta = np.ones(n_features) * 0.1\n",
    "mu_0, sigma = MCUSUMDetector._estimate_incontrol_parameters(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "k = MCUSUMDetector.compute_reference_value_k(delta, sigma)\n",
    "print(k)\n",
    "mcusum = MCUSUMDetector(k=k ) # type: ignore\n",
    "mcusum.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "\n",
    "flags_normal, flags_anomaly = apply_mcusum(\n",
    "\tX_INCONTROL_TEST_PLAY_SCALED,\n",
    "\tX_OUT_OF_CONTROL_TEST_PLAY_SCALED\n",
    ")\n",
    "\n",
    "arl0 = np.argmax(flags_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(flags_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)\n",
    "\n",
    "n = min(len(flags_normal), len(flags_anomaly))\n",
    "print(np.sum(flags_normal[:n] == flags_anomaly[:n]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def345d",
   "metadata": {},
   "source": [
    "**As we see in the plot \"Normal vs Anomaly Overlay\" the fault injection start at the point 160, so we need to cut out the data before this point for both in-control and out-of-control test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d86850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_features = X_INCONTROL_TRAIN_FULL_SCALED.shape[1]\n",
    "delta = np.ones(n_features) * 0.1\n",
    "mu_0, sigma = MCUSUMDetector._estimate_incontrol_parameters(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "k = MCUSUMDetector.compute_reference_value_k(delta, sigma)\n",
    "print(k)\n",
    "\n",
    "mcusum = MCUSUMDetector(k=9, h=3) # type: ignore\n",
    "mcusum.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "\n",
    "fault_injection_point = 160\n",
    "X_INCONTROL_TEST_PLAY_SCALED_CUT = X_INCONTROL_TEST_PLAY_SCALED[fault_injection_point:]\n",
    "X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT = X_OUT_OF_CONTROL_TEST_PLAY_SCALED[fault_injection_point:]\n",
    "\n",
    "flags_normal, flags_anomaly = apply_mcusum(\n",
    "\tX_INCONTROL_TEST_PLAY_SCALED_CUT,\n",
    "\tX_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT\n",
    ")\n",
    "\n",
    "arl0 = np.argmax(flags_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(flags_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"In-control test data shape:\", X_INCONTROL_TEST_PLAY_SCALED.shape)\n",
    "print(\"Cut In-control test data shape:\", X_INCONTROL_TEST_PLAY_SCALED_CUT.shape)\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)\n",
    "\n",
    "n = min(len(flags_normal), len(flags_anomaly))\n",
    "print(np.sum(flags_normal[:n] == flags_anomaly[:n]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba8e3d",
   "metadata": {},
   "source": [
    "### Finding optimal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = None\n",
    "best_arl0 = -np.inf\n",
    "best_arl1 = np.inf\n",
    "\n",
    "k_values = np.linspace(0.1, 10, 30)  # Adjust range and steps as needed\n",
    "\n",
    "for k_test in k_values:\n",
    "    mcusum = MCUSUMDetector(k=k_test, h=2.8)\n",
    "    mcusum.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "    flags_normal, flags_anomaly = apply_mcusum(\n",
    "        X_INCONTROL_TEST_PLAY_SCALED_CUT,\n",
    "        X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT,\n",
    "        verbose=False\n",
    "    )\n",
    "    arl0 = np.argmax(flags_normal == 1) if np.any(flags_normal == 1) else len(flags_normal)\n",
    "    arl1 = np.argmax(flags_anomaly == 1) if np.any(flags_anomaly == 1) else len(flags_anomaly)\n",
    "    \n",
    "    # Prefer higher ARL0, then lower ARL1\n",
    "    if (arl0 > best_arl0) or (arl0 == best_arl0 and arl1 < best_arl1):\n",
    "        best_k = k_test\n",
    "        best_arl0 = arl0\n",
    "        best_arl1 = arl1\n",
    "\n",
    "print(f\"Best k: {best_k}, ARL0: {best_arl0}, ARL1: {best_arl1}\")\n",
    "\n",
    "# Refit with best k and show results\n",
    "mcusum = MCUSUMDetector(k=best_k, h=2.8)\n",
    "mcusum.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "flags_normal, flags_anomaly = apply_mcusum(\n",
    "    X_INCONTROL_TEST_PLAY_SCALED_CUT,\n",
    "    X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT\n",
    ")\n",
    "arl0 = np.argmax(flags_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(flags_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"Final ARL0 (In-control):\", arl0)\n",
    "print(\"Final ARL1 (Out-of-control):\", arl1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_h = None\n",
    "best_arl0 = -np.inf\n",
    "best_arl1 = np.inf\n",
    "\n",
    "# Fix k to a reasonable value, e.g., from previous best_k or a constant\n",
    "fixed_k = best_k  # or set to a specific value, e.g., fixed_k = 6.4\n",
    "\n",
    "h_values = np.linspace(1.0, 10.0, 30)  # Adjust range and steps as needed\n",
    "\n",
    "for h_test in h_values:\n",
    "    mcusum = MCUSUMDetector(k=fixed_k, h=h_test)\n",
    "    mcusum.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "    flags_normal, flags_anomaly = apply_mcusum(\n",
    "        X_INCONTROL_TEST_PLAY_SCALED_CUT,\n",
    "        X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT,\n",
    "        verbose=False\n",
    "    )\n",
    "    arl0 = np.argmax(flags_normal == 1) if np.any(flags_normal == 1) else len(flags_normal)\n",
    "    arl1 = np.argmax(flags_anomaly == 1) if np.any(flags_anomaly == 1) else len(flags_anomaly)\n",
    "    \n",
    "    # Prefer higher ARL0, then lower ARL1\n",
    "    if (arl0 > best_arl0) or (arl0 == best_arl0 and arl1 < best_arl1):\n",
    "        best_h = h_test\n",
    "        best_arl0 = arl0\n",
    "        best_arl1 = arl1\n",
    "\n",
    "print(f\"Best h: {best_h}, ARL0: {best_arl0}, ARL1: {best_arl1}\")\n",
    "\n",
    "# Refit with best h and show results\n",
    "mcusum = MCUSUMDetector(k=fixed_k, h=best_h)\n",
    "mcusum.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "flags_normal, flags_anomaly = apply_mcusum(\n",
    "    X_INCONTROL_TEST_PLAY_SCALED_CUT,\n",
    "    X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT\n",
    ")\n",
    "arl0 = np.argmax(flags_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(flags_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"Final ARL0 (In-control):\", arl0)\n",
    "print(\"Final ARL1 (Out-of-control):\", arl1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = min(len(flags_normal), len(flags_anomaly))\n",
    "print(np.sum(flags_normal[:n] == flags_anomaly[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the feature index to plot (0-based)\n",
    "feature_idx = 10  # Change this to select a different feature\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(X_INCONTROL_TEST_PLAY_SCALED[:, feature_idx], label='In-Control Test Data', color='blue')\n",
    "plt.plot(X_OUT_OF_CONTROL_TEST_PLAY_SCALED[:, feature_idx], label='Out-of-Control Test Data', color='red')\n",
    "plt.title(f'Time Series Plot of Scaled Test Data (Feature {feature_idx})')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Scaled Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611bed26",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "class AutoencoderDetector:\n",
    "    def __init__(self, encoding_dim: int = 8):\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.model: models.Model | None = None\n",
    "        self.threshold: float | None = None\n",
    "        self.X_train: np.ndarray | None = None\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, epochs: int = 50, batch_size: int = 32, threshold_percentile: float = 95):\n",
    "        self.X_train = X_train\n",
    "        input_dim = X_train.shape[1]\n",
    "\n",
    "        input_layer = layers.Input(shape=(input_dim,))\n",
    "        encoded = layers.Dense(16, activation='relu')(input_layer)\n",
    "        encoded = layers.Dense(self.encoding_dim, activation='relu')(encoded)\n",
    "        decoded = layers.Dense(16, activation='relu')(encoded)\n",
    "        decoded = layers.Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "        self.model = models.Model(inputs=input_layer, outputs=decoded)\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        self.model.fit(\n",
    "            X_train,\n",
    "            X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "            validation_split=0.1\n",
    "        )\n",
    "\n",
    "        # Compute threshold from training reconstruction error\n",
    "        X_pred = self.model.predict(X_train)\n",
    "        errors = np.mean((X_train - X_pred) ** 2, axis=1)\n",
    "        self.threshold = np.percentile(errors, threshold_percentile)\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        if self.model is None or self.threshold is None or self.X_train is None:\n",
    "            raise RuntimeError(\"Model not trained. Call fit() first.\")\n",
    "\n",
    "        X_pred = self.model.predict(X_test)\n",
    "        errors = np.mean((X_test - X_pred) ** 2, axis=1)\n",
    "        return (errors > self.threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a567ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_detector = AutoencoderDetector()\n",
    "autoencoder_detector.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90feb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_predictions_anomaly = autoencoder_detector.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "autoencoder_predictions_normal = autoencoder_detector.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(autoencoder_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(autoencoder_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e439764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class AutoencoderDetectorEnhanced:\n",
    "    def __init__(self, encoding_dim: int = 8):\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.model: Optional[models.Model] = None\n",
    "        self.threshold: Optional[float] = None\n",
    "        self.X_train: Optional[np.ndarray] = None\n",
    "        self.scaler_mean: Optional[np.ndarray] = None\n",
    "        self.scaler_std: Optional[np.ndarray] = None\n",
    "        self.history = None\n",
    "        \n",
    "    def _normalize(self, X: np.ndarray, fit: bool = False) -> np.ndarray:\n",
    "        \"\"\"Normalize data using z-score normalization.\"\"\"\n",
    "        if fit:\n",
    "            self.scaler_mean = np.mean(X, axis=0)\n",
    "            self.scaler_std = np.std(X, axis=0) + 1e-7  # Add small epsilon to avoid division by zero\n",
    "        \n",
    "        if self.scaler_mean is None or self.scaler_std is None:\n",
    "            raise RuntimeError(\"Scaler not fitted. This should not happen.\")\n",
    "            \n",
    "        return (X - self.scaler_mean) / self.scaler_std\n",
    "    \n",
    "    def _build_model(self, input_dim: int) -> models.Model:\n",
    "        \"\"\"Build an improved autoencoder architecture.\"\"\"\n",
    "        # Calculate layer dimensions dynamically\n",
    "        layer1_dim = max(input_dim // 2, self.encoding_dim * 4)\n",
    "        layer2_dim = max(input_dim // 4, self.encoding_dim * 2)\n",
    "        \n",
    "        # Encoder\n",
    "        input_layer = layers.Input(shape=(input_dim,))\n",
    "        \n",
    "        # Add noise for denoising autoencoder capability (helps with robustness)\n",
    "        noisy_input = layers.GaussianNoise(0.1)(input_layer)\n",
    "        \n",
    "        # Encoder layers with batch normalization and dropout for regularization\n",
    "        encoded = layers.Dense(\n",
    "            layer1_dim, \n",
    "            activation='relu',\n",
    "            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "            kernel_initializer='he_normal'\n",
    "        )(noisy_input)\n",
    "        encoded = layers.BatchNormalization()(encoded)\n",
    "        encoded = layers.Dropout(0.2)(encoded)\n",
    "        \n",
    "        encoded = layers.Dense(\n",
    "            layer2_dim, \n",
    "            activation='relu',\n",
    "            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "            kernel_initializer='he_normal'\n",
    "        )(encoded)\n",
    "        encoded = layers.BatchNormalization()(encoded)\n",
    "        encoded = layers.Dropout(0.2)(encoded)\n",
    "        \n",
    "        # Bottleneck layer\n",
    "        encoded = layers.Dense(\n",
    "            self.encoding_dim, \n",
    "            activation='relu',\n",
    "            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "            kernel_initializer='he_normal',\n",
    "            name='bottleneck'\n",
    "        )(encoded)\n",
    "        \n",
    "        # Decoder layers (symmetric to encoder)\n",
    "        decoded = layers.Dense(\n",
    "            layer2_dim, \n",
    "            activation='relu',\n",
    "            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "            kernel_initializer='he_normal'\n",
    "        )(encoded)\n",
    "        decoded = layers.BatchNormalization()(decoded)\n",
    "        decoded = layers.Dropout(0.2)(decoded)\n",
    "        \n",
    "        decoded = layers.Dense(\n",
    "            layer1_dim, \n",
    "            activation='relu',\n",
    "            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "            kernel_initializer='he_normal'\n",
    "        )(decoded)\n",
    "        decoded = layers.BatchNormalization()(decoded)\n",
    "        decoded = layers.Dropout(0.2)(decoded)\n",
    "        \n",
    "        # Output layer with tanh activation (works better with normalized data)\n",
    "        decoded = layers.Dense(\n",
    "            input_dim, \n",
    "            activation='tanh',\n",
    "            kernel_initializer='glorot_uniform'\n",
    "        )(decoded)\n",
    "        \n",
    "        model = models.Model(inputs=input_layer, outputs=decoded)\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, epochs: int = 50, batch_size: int = 32, \n",
    "            threshold_percentile: float = 95) -> None:\n",
    "        \"\"\"\n",
    "        Train the autoencoder on normal data.\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training data (assumed to be mostly normal samples)\n",
    "            epochs: Number of training epochs\n",
    "            batch_size: Batch size for training\n",
    "            threshold_percentile: Percentile for threshold calculation\n",
    "        \"\"\"\n",
    "        # Normalize the training data\n",
    "        X_train_normalized = self._normalize(X_train, fit=True)\n",
    "        self.X_train = X_train_normalized\n",
    "        \n",
    "        input_dim = X_train.shape[1]\n",
    "        \n",
    "        # Build the model\n",
    "        self.model = self._build_model(input_dim)\n",
    "        \n",
    "        # Use a custom learning rate schedule\n",
    "        initial_learning_rate = 0.001\n",
    "        lr_schedule = callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping to prevent overfitting\n",
    "        early_stopping = callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Compile with Adam optimizer with custom learning rate\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer, \n",
    "            loss='mse',\n",
    "            metrics=['mae']  # Add MAE as additional metric\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        self.history = self.model.fit(\n",
    "            X_train_normalized,\n",
    "            X_train_normalized,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "            validation_split=0.15,  # Slightly larger validation split\n",
    "            callbacks=[lr_schedule, early_stopping],\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # Compute reconstruction errors for threshold calculation\n",
    "        X_pred = self.model.predict(X_train_normalized, verbose=0)\n",
    "        \n",
    "        # Calculate reconstruction error using multiple metrics\n",
    "        mse_errors = np.mean((X_train_normalized - X_pred) ** 2, axis=1)\n",
    "        mae_errors = np.mean(np.abs(X_train_normalized - X_pred), axis=1)\n",
    "        \n",
    "        # Combine errors (weighted average of MSE and MAE)\n",
    "        combined_errors = 0.7 * mse_errors + 0.3 * mae_errors\n",
    "        \n",
    "        # Set threshold using the specified percentile\n",
    "        self.threshold = np.percentile(combined_errors, threshold_percentile)\n",
    "        \n",
    "        # Store some statistics for potential debugging\n",
    "        self.error_stats = {\n",
    "            'mean': np.mean(combined_errors),\n",
    "            'std': np.std(combined_errors),\n",
    "            'min': np.min(combined_errors),\n",
    "            'max': np.max(combined_errors),\n",
    "            'threshold': self.threshold\n",
    "        }\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict anomalies in test data.\n",
    "        \n",
    "        Args:\n",
    "            X_test: Test data to check for anomalies\n",
    "            \n",
    "        Returns:\n",
    "            Binary array where 1 indicates anomaly, 0 indicates normal\n",
    "        \"\"\"\n",
    "        if self.model is None or self.threshold is None or self.X_train is None:\n",
    "            raise RuntimeError(\"Model not trained. Call fit() first.\")\n",
    "        \n",
    "        # Normalize test data using training statistics\n",
    "        X_test_normalized = self._normalize(X_test, fit=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        X_pred = self.model.predict(X_test_normalized, verbose=0)\n",
    "        \n",
    "        # Calculate reconstruction errors (same combination as in training)\n",
    "        mse_errors = np.mean((X_test_normalized - X_pred) ** 2, axis=1)\n",
    "        mae_errors = np.mean(np.abs(X_test_normalized - X_pred), axis=1)\n",
    "        combined_errors = 0.7 * mse_errors + 0.3 * mae_errors\n",
    "        \n",
    "        # Return binary predictions\n",
    "        return (combined_errors > self.threshold).astype(int)\n",
    "    \n",
    "    def get_anomaly_scores(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get anomaly scores (reconstruction errors) for test data.\n",
    "        \n",
    "        Args:\n",
    "            X_test: Test data\n",
    "            \n",
    "        Returns:\n",
    "            Array of anomaly scores (higher = more anomalous)\n",
    "        \"\"\"\n",
    "        if self.model is None or self.X_train is None:\n",
    "            raise RuntimeError(\"Model not trained. Call fit() first.\")\n",
    "        \n",
    "        # Normalize test data\n",
    "        X_test_normalized = self._normalize(X_test, fit=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        X_pred = self.model.predict(X_test_normalized, verbose=0)\n",
    "        \n",
    "        # Calculate and return reconstruction errors\n",
    "        mse_errors = np.mean((X_test_normalized - X_pred) ** 2, axis=1)\n",
    "        mae_errors = np.mean(np.abs(X_test_normalized - X_pred), axis=1)\n",
    "        combined_errors = 0.7 * mse_errors + 0.3 * mae_errors\n",
    "        \n",
    "        return combined_errors\n",
    "    \n",
    "    def get_encoder_output(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the encoded representation of input data.\n",
    "        \n",
    "        Args:\n",
    "            X: Input data\n",
    "            \n",
    "        Returns:\n",
    "            Encoded representation from the bottleneck layer\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not trained. Call fit() first.\")\n",
    "        \n",
    "        # Create encoder model\n",
    "        encoder = models.Model(\n",
    "            inputs=self.model.input,\n",
    "            outputs=self.model.get_layer('bottleneck').output\n",
    "        )\n",
    "        \n",
    "        # Normalize and encode\n",
    "        X_normalized = self._normalize(X, fit=False)\n",
    "        return encoder.predict(X_normalized, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d709c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_detector_enhanced = AutoencoderDetectorEnhanced()\n",
    "autoencoder_detector_enhanced.fit(X_INCONTROL_TRAIN_FULL_SCALED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_predictions_anomaly = autoencoder_detector_enhanced.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "autoencoder_predictions_normal = autoencoder_detector_enhanced.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(autoencoder_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(autoencoder_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634dffc5",
   "metadata": {},
   "source": [
    "## EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e831c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Define classes for MEWMA variants\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class BaseEWMA:\n",
    "    \"\"\"\n",
    "    Base class for EWMA-type multivariate control charts.\n",
    "    Handles training mean and covariance estimation,\n",
    "    and provides attributes used by specific MEWMA variants.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_: float = 0.2, percentile: float = 99.5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        lambda_ : float\n",
    "            Smoothing parameter for EWMA (0 < lambda_ <= 1).\n",
    "            Higher values react faster to changes.\n",
    "        percentile : float\n",
    "            Percentile of in-control distribution used to set control limit.\n",
    "        \"\"\"\n",
    "        self.lambda_ = lambda_\n",
    "        self.percentile = percentile\n",
    "        self.mu0 = None           # In-control mean vector\n",
    "        self.p = None             # Number of variables\n",
    "        self.Sigma = None         # In-control covariance matrix\n",
    "        self.Sigma_inv = None     # Inverse covariance\n",
    "        self.h = None             # Control limit threshold\n",
    "\n",
    "    def fit(self, X_train: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Estimate in-control parameters from training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray of shape (n_samples, n_features)\n",
    "            In-control training observations.\n",
    "        \"\"\"\n",
    "        self.mu0 = np.mean(X_train, axis=0)\n",
    "        self.p = X_train.shape[1]\n",
    "        self.Sigma = np.cov(X_train.T)\n",
    "        self.Sigma_inv = np.linalg.inv(self.Sigma)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6f282",
   "metadata": {},
   "source": [
    "### MEWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcdf50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardMEWMA(BaseEWMA):\n",
    "    \"\"\"\n",
    "    Standard Multivariate EWMA (MEWMA) Control Chart.\n",
    "\n",
    "    Monitors the smoothed mean vector of a multivariate process.\n",
    "    Detection statistic is a Hotelling-type TÂ² on the EWMA vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X_train: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Train the MEWMA chart on in-control data.\n",
    "        Estimates the empirical distribution of the monitoring statistic\n",
    "        and sets the control limit threshold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray of shape (n_samples, n_features)\n",
    "            In-control training data.\n",
    "        \"\"\"\n",
    "        # Step 1: Fit base parameters (mean, covariance, inverse covariance)\n",
    "        super().fit(X_train)\n",
    "\n",
    "        # Step 2: Initialize smoothed deviation vector Z\n",
    "        n = X_train.shape[0]\n",
    "        Z = np.zeros(self.p)\n",
    "        Ts = []  # store monitoring statistics\n",
    "\n",
    "        # Step 3: Iterate through training samples\n",
    "        for i in range(n):\n",
    "            # Deviation from in-control mean\n",
    "            g = X_train[i] - self.mu0\n",
    "\n",
    "            # Update EWMA vector\n",
    "            Z = self.lambda_ * g + (1 - self.lambda_) * Z\n",
    "\n",
    "            # Step 4: Monitoring statistic\n",
    "            # Hotelling-type quadratic form, scaled by factor (2 - Î»)/Î»\n",
    "            T = ((2 - self.lambda_) / self.lambda_) * np.dot(Z, self.Sigma_inv @ Z)\n",
    "            Ts.append(T)\n",
    "\n",
    "        # Step 5: Set control limit from empirical distribution\n",
    "        self.h = np.percentile(Ts, self.percentile) if Ts else np.inf\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply the trained MEWMA chart to new observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_samples, n_features)\n",
    "            Test sequence of observations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred : np.ndarray of shape (n_samples,)\n",
    "            Boolean array: True if alarm (out-of-control), False otherwise.\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        Z = np.zeros(self.p)\n",
    "        pred = np.zeros(n, dtype=bool)\n",
    "\n",
    "        for i in range(n):\n",
    "            # Deviation from in-control mean\n",
    "            g = X[i] - self.mu0\n",
    "\n",
    "            # Update EWMA vector\n",
    "            Z = self.lambda_ * g + (1 - self.lambda_) * Z\n",
    "\n",
    "            # Compute monitoring statistic\n",
    "            T = ((2 - self.lambda_) / self.lambda_) * np.dot(Z, self.Sigma_inv @ Z)\n",
    "\n",
    "            # Compare against control limit\n",
    "            pred[i] = T > self.h\n",
    "\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mewma = StandardMEWMA()\n",
    "mewma.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "mewma_predictions_normal = mewma.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "mewma_predictions_anomaly = mewma.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(mewma_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(mewma_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b0eca",
   "metadata": {},
   "source": [
    "### MEWMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23887b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEWMS(BaseEWMA):\n",
    "    \"\"\"\n",
    "    Multivariate Exponentially Weighted Moving Covariance (MEWMS) Chart.\n",
    "\n",
    "    Monitors changes in the covariance structure by smoothing\n",
    "    the outer product of deviations, standardized by the in-control covariance.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X_train: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Train the MEWMS chart on in-control data.\n",
    "        Estimates the distribution of the monitoring statistic\n",
    "        and sets the control limit threshold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            In-control training data.\n",
    "        \"\"\"\n",
    "        # Step 1: Fit base parameters (mean, covariance, inverse covariance)\n",
    "        super().fit(X_train)\n",
    "\n",
    "        # Step 2: Initialize smoothed covariance statistic Y\n",
    "        # Y is a weighted moving average of outer products of deviations\n",
    "        n = X_train.shape[0]\n",
    "        Y = np.zeros((self.p, self.p))\n",
    "        Ts = []  # store monitoring statistics for threshold estimation\n",
    "\n",
    "        # Step 3: Iterate through training samples\n",
    "        for i in range(n):\n",
    "            # Deviation from in-control mean\n",
    "            g = X_train[i] - self.mu0\n",
    "\n",
    "            # Update smoothed covariance estimate (EWMA form)\n",
    "            Y = self.lambda_ * np.outer(g, g) + (1 - self.lambda_) * Y\n",
    "\n",
    "            # Step 4: Monitoring statistic (standardized quadratic form)\n",
    "            # Using trace(Sigma_inv @ Y) normalizes by in-control variance/correlation\n",
    "            T = np.trace(self.Sigma_inv @ Y)\n",
    "            Ts.append(T)\n",
    "\n",
    "        # Step 5: Set control limit from empirical distribution\n",
    "        # Use high percentile of in-control statistic as threshold\n",
    "        self.h = np.percentile(Ts, self.percentile) if Ts else np.inf\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply the trained MEWMS chart to new observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_samples, n_features)\n",
    "            Test sequence of observations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred : np.ndarray of shape (n_samples,)\n",
    "            Boolean array: True if alarm (out-of-control), False otherwise.\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        Y = np.zeros((self.p, self.p))\n",
    "        pred = np.zeros(n, dtype=bool)\n",
    "\n",
    "        for i in range(n):\n",
    "            # Deviation from in-control mean\n",
    "            g = X[i] - self.mu0\n",
    "\n",
    "            # Update smoothed covariance statistic\n",
    "            Y = self.lambda_ * np.outer(g, g) + (1 - self.lambda_) * Y\n",
    "\n",
    "            # Compute standardized monitoring statistic\n",
    "            T = np.trace(self.Sigma_inv @ Y)\n",
    "\n",
    "            # Compare against control limit\n",
    "            pred[i] = T > self.h\n",
    "\n",
    "        return pred.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad969c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mewms = MEWMS()\n",
    "mewms.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "mewms_predictions_normal = mewms.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "mewms_predictions_anomaly = mewms.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(mewms_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(mewms_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba288a",
   "metadata": {},
   "source": [
    "### MEWMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548be6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MEWMV(BaseEWMA):\n",
    "    \"\"\"\n",
    "    Multivariate EWMA for Mean and Variance (MEWMV) Control Chart.\n",
    "\n",
    "    Monitors both:\n",
    "    - Mean shifts (via smoothed EWMA vector Z)\n",
    "    - Variance/covariance changes (via smoothed covariance matrix S)\n",
    "\n",
    "    Detection statistic combines the standardized mean part (Hotelling-type)\n",
    "    and the variance part (scaled covariance trace).\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X_train: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Train the MEWMV chart on in-control data.\n",
    "        Estimates the empirical distribution of the monitoring statistic\n",
    "        and sets the control limit threshold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray of shape (n_samples, n_features)\n",
    "            In-control training data.\n",
    "        \"\"\"\n",
    "        # Step 1: Fit base parameters (mean, covariance, inverse covariance)\n",
    "        super().fit(X_train)\n",
    "\n",
    "        # Step 2: Initialize smoothed mean and variance statistics\n",
    "        n = X_train.shape[0]\n",
    "        Z = np.zeros(self.p)               # EWMA mean shift vector\n",
    "        S = np.zeros((self.p, self.p))     # EWMA covariance estimate\n",
    "        Ts = []\n",
    "\n",
    "        # Step 3: Iterate through training samples\n",
    "        for i in range(n):\n",
    "            # Mean deviation\n",
    "            g_mean = X_train[i] - self.mu0\n",
    "\n",
    "            # Update smoothed mean shift (EWMA form)\n",
    "            Z = self.lambda_ * g_mean + (1 - self.lambda_) * Z\n",
    "\n",
    "            # Update smoothed covariance contribution\n",
    "            g_var = np.outer(g_mean, g_mean)\n",
    "            S = self.lambda_ * g_var + (1 - self.lambda_) * S\n",
    "\n",
    "            # Step 4: Monitoring statistic\n",
    "            # Mean part: standardized quadratic form\n",
    "            T_mean = ((2 - self.lambda_) / self.lambda_) * np.dot(Z, self.Sigma_inv @ Z)\n",
    "\n",
    "            # Variance part: standardized covariance trace\n",
    "            # Using trace(Sigma_inv @ S) instead of raw trace(S)\n",
    "            T_var = np.trace(self.Sigma_inv @ S)\n",
    "\n",
    "            # Combined statistic\n",
    "            T = T_mean + T_var\n",
    "            Ts.append(T)\n",
    "\n",
    "        # Step 5: Set control limit from empirical in-control distribution\n",
    "        self.h = np.percentile(Ts, self.percentile) if Ts else np.inf\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply the trained MEWMV chart to new observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_samples, n_features)\n",
    "            Test sequence of observations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred : np.ndarray of shape (n_samples,)\n",
    "            Boolean array: True if alarm (out-of-control), False otherwise.\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        Z = np.zeros(self.p)\n",
    "        S = np.zeros((self.p, self.p))\n",
    "        pred = np.zeros(n, dtype=bool)\n",
    "\n",
    "        for i in range(n):\n",
    "            # Mean deviation\n",
    "            g_mean = X[i] - self.mu0\n",
    "\n",
    "            # Update smoothed mean\n",
    "            Z = self.lambda_ * g_mean + (1 - self.lambda_) * Z\n",
    "\n",
    "            # Update smoothed covariance\n",
    "            g_var = np.outer(g_mean, g_mean)\n",
    "            S = self.lambda_ * g_var + (1 - self.lambda_) * S\n",
    "\n",
    "            # Monitoring statistic\n",
    "            T_mean = ((2 - self.lambda_) / self.lambda_) * np.dot(Z, self.Sigma_inv @ Z)\n",
    "            T_var = np.trace(self.Sigma_inv @ S)\n",
    "            T = T_mean + T_var\n",
    "\n",
    "            # Compare against control limit\n",
    "            pred[i] = T > self.h\n",
    "\n",
    "        return pred.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5561c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mewmv = MEWMV()\n",
    "mewmv.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "mewmv_predictions_normal = mewmv.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "mewmv_predictions_anomaly = mewmv.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(mewmv_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(mewmv_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ea79d",
   "metadata": {},
   "source": [
    "### REWMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c46633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class REWMV(BaseEWMA):\n",
    "    \"\"\"\n",
    "    Robust EWMA for Monitoring Variance (REWMV).\n",
    "\n",
    "    Focuses on detecting variance shifts in multivariate processes.\n",
    "    Uses log-squared deviations to reduce the impact of outliers,\n",
    "    then applies EWMA smoothing and sums across dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X_train: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Train the REWMV chart on in-control data.\n",
    "        Estimates the empirical distribution of the monitoring statistic\n",
    "        and sets the control limit threshold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray of shape (n_samples, n_features)\n",
    "            In-control training data.\n",
    "        \"\"\"\n",
    "        # Step 1: Fit base parameters (mean, covariance, inverse covariance)\n",
    "        super().fit(X_train)\n",
    "\n",
    "        # Step 2: Initialize smoothed log-variance vector\n",
    "        n = X_train.shape[0]\n",
    "        Y = np.zeros(self.p)   # EWMA of log-squared deviations\n",
    "        Ts = []\n",
    "\n",
    "        # Step 3: Iterate through training samples\n",
    "        for i in range(n):\n",
    "            # Squared deviation from mean\n",
    "            diffs = (X_train[i] - self.mu0) ** 2\n",
    "\n",
    "            # Log-transform (robust variance signal)\n",
    "            g = np.log(diffs + 1e-10)  # Add small constant to avoid log(0)\n",
    "\n",
    "            # Update smoothed statistic\n",
    "            Y = self.lambda_ * g + (1 - self.lambda_) * Y\n",
    "\n",
    "            # Step 4: Monitoring statistic\n",
    "            # Sum across dimensions â†’ global variance change measure\n",
    "            T = np.sum(Y)\n",
    "            Ts.append(T)\n",
    "\n",
    "        # Step 5: Control limit\n",
    "        self.h = np.percentile(Ts, self.percentile) if Ts else np.inf\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply the trained REWMV chart to new observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_samples, n_features)\n",
    "            Test sequence of observations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred : np.ndarray of shape (n_samples,)\n",
    "            Boolean array: True if alarm (out-of-control), False otherwise.\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        Y = np.zeros(self.p)\n",
    "        pred = np.zeros(n, dtype=bool)\n",
    "\n",
    "        for i in range(n):\n",
    "            # Squared deviation\n",
    "            diffs = (X[i] - self.mu0) ** 2\n",
    "\n",
    "            # Log transform\n",
    "            g = np.log(diffs + 1e-10)\n",
    "\n",
    "            # Update smoothed statistic\n",
    "            Y = self.lambda_ * g + (1 - self.lambda_) * Y\n",
    "\n",
    "            # Monitoring statistic\n",
    "            T = np.sum(Y)\n",
    "\n",
    "            # Compare to control limit\n",
    "            pred[i] = T > self.h\n",
    "\n",
    "        return pred.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56878ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewmv = REWMV()\n",
    "rewmv.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "rewmv_predictions_normal = rewmv.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "rewmv_predictions_anomaly = rewmv.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(rewmv_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(rewmv_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033b221",
   "metadata": {},
   "source": [
    "### MAX MEWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxMEWMV:\n",
    "    \"\"\"\n",
    "    Maximum Multivariate Exponentially Weighted Moving Variance (MaxMEWMV) Control Chart.\n",
    "\n",
    "    This method extends the concept of MEWMA (Multivariate EWMA) by monitoring\n",
    "    the variance structure of the process over time. Instead of only tracking\n",
    "    shifts in the mean vector, it is also sensitive to covariance changes.\n",
    "\n",
    "    Output: Binary classification\n",
    "        - 0 â†’ In-control (normal)\n",
    "        - 1 â†’ Out-of-control (anomaly)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_: float = 0.2, threshold: float = 10.0) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MaxMEWMV chart.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lambda_ : float, default=0.2\n",
    "            Smoothing parameter (0 < lambda_ â‰¤ 1).\n",
    "            Small values â†’ long memory (slower adaptation).\n",
    "            Large values â†’ short memory (faster adaptation).\n",
    "        threshold : float, default=10.0\n",
    "            Control limit threshold. Values above this\n",
    "            are classified as anomalies.\n",
    "        \"\"\"\n",
    "        self.lambda_: float = lambda_\n",
    "        self.threshold: float = threshold\n",
    "        self.mu0: Optional[np.ndarray] = None\n",
    "        self.cov0: Optional[np.ndarray] = None\n",
    "        self.stat_history: list[float] = []\n",
    "\n",
    "    def fit(self, X_train: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Fit the MaxMEWMV chart using in-control training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            2D array of shape (n_samples, n_features).\n",
    "            Assumed to represent only in-control (normal) observations.\n",
    "        \"\"\"\n",
    "        # Ensure input is 2D\n",
    "        if X_train.ndim != 2:\n",
    "            raise ValueError(\"X_train must be a 2D array.\")\n",
    "\n",
    "        # Store baseline mean and covariance (in-control reference)\n",
    "        self.mu0 = np.mean(X_train, axis=0)\n",
    "        self.cov0 = np.cov(X_train, rowvar=False)\n",
    "\n",
    "        # Initialize monitoring statistic with zero\n",
    "        n_features: int = X_train.shape[1]\n",
    "        self.stat_history = [0.0] * n_features\n",
    "\n",
    "        # Iterate over each sample in training to initialize control structure\n",
    "        for i in range(X_train.shape[0]):\n",
    "            deviation: np.ndarray = X_train[i] - self.mu0\n",
    "            g: np.ndarray = np.outer(deviation, deviation)\n",
    "\n",
    "            # Update exponentially weighted moving variance statistics\n",
    "            self.stat_history = (\n",
    "                self.lambda_ * np.diag(g) + (1 - self.lambda_) * np.array(self.stat_history)\n",
    "            ).tolist()\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict anomalies in new data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            2D array of shape (n_samples, n_features).\n",
    "            Test or monitoring data (may include anomalies).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            1D array of shape (n_samples,) with binary predictions:\n",
    "            - 0 â†’ Normal (in-control)\n",
    "            - 1 â†’ Anomaly (out-of-control)\n",
    "        \"\"\"\n",
    "        if self.mu0 is None or self.cov0 is None:\n",
    "            raise RuntimeError(\"Model must be fitted before prediction.\")\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        predictions: list[int] = []\n",
    "\n",
    "        # Initialize local monitoring statistic\n",
    "        stat_local: list[float] = [0.0] * n_features\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            deviation: np.ndarray = X[i] - self.mu0\n",
    "            g: np.ndarray = np.outer(deviation, deviation)\n",
    "\n",
    "            # Update variance statistics\n",
    "            stat_local = (\n",
    "                self.lambda_ * np.diag(g) + (1 - self.lambda_) * np.array(stat_local)\n",
    "            ).tolist()\n",
    "\n",
    "            # Use maximum variance component as monitoring statistic\n",
    "            stat_value: float = float(np.max(stat_local))\n",
    "\n",
    "            # Apply threshold to generate binary classification\n",
    "            if stat_value > self.threshold:\n",
    "                predictions.append(1)  # anomaly\n",
    "            else:\n",
    "                predictions.append(0)  # normal\n",
    "\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c455afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mewmv = MaxMEWMV()\n",
    "max_mewmv.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "max_mewmv_predictions_normal = max_mewmv.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "max_mewmv_predictions_anomaly = max_mewmv.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(max_mewmv_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(max_mewmv_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d0378",
   "metadata": {},
   "source": [
    "### MNSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNSE(BaseEWMA):\n",
    "    def fit(self, X_train: np.ndarray):\n",
    "        super().fit(X_train)\n",
    "        n = X_train.shape[0]\n",
    "        Y = np.zeros(self.p)\n",
    "        Ts = []\n",
    "        for i in range(n):\n",
    "            diff = X_train[i] - self.mu0\n",
    "            norm = np.linalg.norm(diff)\n",
    "            g = diff / norm if norm > 1e-10 else np.zeros(self.p)\n",
    "            Y = self.lambda_ * g + (1 - self.lambda_) * Y\n",
    "            T = np.dot(Y, Y)\n",
    "            Ts.append(T)\n",
    "        self.h = np.percentile(Ts, self.percentile) if Ts else np.inf\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        n = X.shape[0]\n",
    "        Y = np.zeros(self.p)\n",
    "        pred = np.zeros(n, dtype=bool)\n",
    "        for i in range(n):\n",
    "            diff = X[i] - self.mu0\n",
    "            norm = np.linalg.norm(diff)\n",
    "            g = diff / norm if norm > 1e-10 else np.zeros(self.p)\n",
    "            Y = self.lambda_ * g + (1 - self.lambda_) * Y\n",
    "            T = np.dot(Y, Y)\n",
    "            pred[i] = T > self.h\n",
    "        return pred.astype(int)\n",
    "\n",
    "# For adaptive variants, providing placeholders as they require additional logic\n",
    "\n",
    "class AEWMA(StandardMEWMA):\n",
    "    # Placeholder for AEWMA: lambda varies based on recent T_t\n",
    "    # For simplicity, uses fixed lambda; extend with adaptive logic if needed\n",
    "    pass\n",
    "\n",
    "class SAMEWMA(StandardMEWMA):\n",
    "    # Placeholder for SAMEWMA: integrate with external ML model\n",
    "    # Example: def set_lambda(self, ml_model_prediction): ...\n",
    "    pass\n",
    "\n",
    "class AMFEWMA(StandardMEWMA):\n",
    "    # Placeholder for AMFEWMA: similar to standard for multivariate; extend for basis coefficients if data is functional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnse = MNSE()\n",
    "mnse.fit(X_INCONTROL_TRAIN_FULL_SCALED)\n",
    "mnse_predictions_normal = mnse.predict(X_INCONTROL_TEST_PLAY_SCALED_CUT)\n",
    "mnse_predictions_anomaly = mnse.predict(X_OUT_OF_CONTROL_TEST_PLAY_SCALED_CUT)\n",
    "\n",
    "arl0 = np.argmax(mnse_predictions_normal == 1) if np.any(flags_normal == 1) else None\n",
    "arl1 = np.argmax(mnse_predictions_anomaly == 1) if np.any(flags_anomaly == 1) else None\n",
    "\n",
    "print(\"ARL0 (In-control):\", arl0)\n",
    "print(\"ARL1 (Out-of-control):\", arl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79ff27",
   "metadata": {},
   "source": [
    "## Run with all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13dc510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_first_false_alarm_index(flags_normal):\n",
    "    if np.any(flags_normal == 1):\n",
    "        return int(np.argmax(flags_normal == 1))\n",
    "    return None\n",
    "\n",
    "def get_first_detection_delay(flags_anomaly):\n",
    "    if np.any(flags_anomaly == 1):\n",
    "        return int(np.argmax(flags_anomaly == 1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATION_RUN_RANGE = range(1, 21)\n",
    "FAULT_NUMBER_RANGE = range(1, 21)\n",
    "\n",
    "results: List[Dict[str, Any]] = []\n",
    "\n",
    "# Add to MODELS dictionary\n",
    "\n",
    "# Dictionary of models for extensibility\n",
    "MODELS = {\n",
    "    \"MCUSUM\": mcusum_predict,\n",
    "    \"Autoencoder\": autoencoder_detector.predict,\n",
    "    \"AutoencoderEnhanced\": autoencoder_detector_enhanced.predict,\n",
    "    # \"MEWMS\": mewms.predict\n",
    "}\n",
    "\n",
    "for simulation_run in SIMULATION_RUN_RANGE:\n",
    "    DF_FF_TRAINING_SEQUENCED = DF_FF_TRAINING_RAW.query(\"simulationRun == @simulation_run\")\n",
    "    DF_FF_TEST_SEQUENCED = DF_FF_TEST_RAW.query(\"simulationRun == @simulation_run\")\n",
    "\n",
    "    # In-control data\n",
    "    X_INCONTROL_TRAIN_DF = DF_FF_TRAINING_SEQUENCED.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "    X_INCONTROL_TEST_DF = DF_FF_TEST_SEQUENCED.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "    scaler_incontrol.fit(X_INCONTROL_TRAIN_DF)\n",
    "    X_INCONTROL_TRAIN_SCALED = scaler_incontrol.transform(X_INCONTROL_TRAIN_DF)[fault_injection_point:]\n",
    "    X_INCONTROL_TEST_SCALED = scaler_incontrol.transform(X_INCONTROL_TEST_DF)[fault_injection_point:]\n",
    "\n",
    "    # Precompute in-control predictions once per simulation run\n",
    "    pred_normal_dict = {}\n",
    "    for model_name, model_func in MODELS.items():\n",
    "        pred_normal_dict[model_name] = model_func(X_INCONTROL_TEST_SCALED)\n",
    "\n",
    "    for fault_number in FAULT_NUMBER_RANGE:\n",
    "        DF_F_TRAINING_SEQUENCED = DF_F_TRAINING_RAW.query(\n",
    "            \"faultNumber == @fault_number and simulationRun == @simulation_run\"\n",
    "        )\n",
    "        DF_F_TEST_SEQUENCED = DF_F_TEST_RAW.query(\n",
    "            \"faultNumber == @fault_number and simulationRun == @simulation_run\"\n",
    "        )\n",
    "\n",
    "        # Out-of-control data\n",
    "        X_OUT_OF_CONTROL_TEST_DF = DF_F_TEST_SEQUENCED.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "        X_OUT_OF_CONTROL_TRAIN_DF = DF_F_TRAINING_SEQUENCED.drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "        X_OUT_OF_CONTROL_TEST_SCALED = scaler_incontrol.transform(X_OUT_OF_CONTROL_TEST_DF)[fault_injection_point:]\n",
    "        X_OUT_OF_CONTROL_TRAIN_SCALED = scaler_incontrol.transform(X_OUT_OF_CONTROL_TRAIN_DF)[fault_injection_point:]\n",
    "\n",
    "        # Run all models\n",
    "        for model_name, model_func in MODELS.items():\n",
    "            pred_anomaly = model_func(X_OUT_OF_CONTROL_TEST_SCALED)\n",
    "            pred_normal = pred_normal_dict[model_name]\n",
    "\n",
    "            arl1 = get_first_detection_delay(pred_anomaly)\n",
    "            arl0 = get_first_false_alarm_index(pred_normal)\n",
    "\n",
    "            print(f\"**Simulation Run: {simulation_run}, Fault Number: {fault_number}, Model: {model_name}**\")\n",
    "            print(f\"ARL0 (False Alarm): {arl0} ARL1 (Detection Delay): {arl1}\")\n",
    "            print()\n",
    "\n",
    "            detection_fraction = np.mean(pred_anomaly)\n",
    "\n",
    "            results.append({\n",
    "                \"simulationRun\": simulation_run,\n",
    "                \"faultNumber\": fault_number,\n",
    "                \"model\": model_name,\n",
    "                \"ARL0\": arl0,\n",
    "                \"ARL1\": arl1,\n",
    "                \"detection_fraction\": detection_fraction\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame and aggregate metrics (unchanged)\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "grouped = df_results.groupby(['model', 'faultNumber'])\n",
    "conditional_arl0 = grouped['ARL0'].apply(lambda x: x.dropna().mean() if not x.dropna().empty else np.nan)\n",
    "sdrl0 = grouped['ARL0'].apply(lambda x: x.dropna().std() if len(x.dropna()) > 1 else np.nan)\n",
    "non_fa_fraction = grouped['ARL0'].apply(lambda x: x.isnull().mean())\n",
    "conditional_arl1 = grouped['ARL1'].apply(lambda x: x.dropna().mean() if not x.dropna().empty else np.nan)\n",
    "sdrl1 = grouped['ARL1'].apply(lambda x: x.dropna().std() if len(x.dropna()) > 1 else np.nan)\n",
    "non_detection_fraction = grouped['ARL1'].apply(lambda x: x.isnull().mean())\n",
    "avg_detection_fraction = grouped['detection_fraction'].mean()\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'conditional_ARL0': conditional_arl0,\n",
    "    'SDRL0': sdrl0,\n",
    "    'non_FA_fraction': non_fa_fraction,\n",
    "    'conditional_ARL1': conditional_arl1,\n",
    "    'SDRL1': sdrl1,\n",
    "    'non_detection_fraction': non_detection_fraction,\n",
    "    'avg_detection_fraction': avg_detection_fraction\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90168ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ModelComparisonAnalyzer:\n",
    "    \"\"\"Class to analyze and visualize model comparison results.\"\"\"\n",
    "    \n",
    "    def __init__(self, df_results: pd.DataFrame, summary_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with results data.\n",
    "        \n",
    "        Args:\n",
    "            df_results: DataFrame with raw results from all simulation runs\n",
    "            summary_df: DataFrame with aggregated summary statistics\n",
    "        \"\"\"\n",
    "        self.df_results = df_results\n",
    "        self.summary_df = summary_df\n",
    "        self.models = df_results['model'].unique()\n",
    "        self.fault_numbers = sorted(df_results['faultNumber'].unique())\n",
    "        \n",
    "    def create_comparison_table(self, metric: str = 'all') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a detailed comparison table for specified metrics.\n",
    "        \n",
    "        Args:\n",
    "            metric: 'ARL0', 'ARL1', 'detection', or 'all'\n",
    "        \n",
    "        Returns:\n",
    "            Formatted comparison DataFrame\n",
    "        \"\"\"\n",
    "        if metric == 'all':\n",
    "            # Create comprehensive comparison table\n",
    "            pivot_tables = []\n",
    "            \n",
    "            # ARL1 comparison\n",
    "            arl1_pivot = self.summary_df.pivot(\n",
    "                index='faultNumber', \n",
    "                columns='model', \n",
    "                values='conditional_ARL1'\n",
    "            ).round(2)\n",
    "            arl1_pivot.columns = [f'{col}_ARL1' for col in arl1_pivot.columns]\n",
    "            pivot_tables.append(arl1_pivot)\n",
    "            \n",
    "            # ARL0 comparison\n",
    "            arl0_pivot = self.summary_df.pivot(\n",
    "                index='faultNumber', \n",
    "                columns='model', \n",
    "                values='conditional_ARL0'\n",
    "            ).round(2)\n",
    "            arl0_pivot.columns = [f'{col}_ARL0' for col in arl0_pivot.columns]\n",
    "            pivot_tables.append(arl0_pivot)\n",
    "            \n",
    "            # Detection fraction comparison\n",
    "            det_pivot = self.summary_df.pivot(\n",
    "                index='faultNumber', \n",
    "                columns='model', \n",
    "                values='avg_detection_fraction'\n",
    "            ).round(3)\n",
    "            det_pivot.columns = [f'{col}_DetFrac' for col in det_pivot.columns]\n",
    "            pivot_tables.append(det_pivot)\n",
    "            \n",
    "            # Combine all metrics\n",
    "            comparison_table = pd.concat(pivot_tables, axis=1)\n",
    "            comparison_table.index.name = 'Fault'\n",
    "            \n",
    "            return comparison_table\n",
    "        \n",
    "        elif metric == 'ARL1':\n",
    "            return self._create_arl1_table()\n",
    "        elif metric == 'ARL0':\n",
    "            return self._create_arl0_table()\n",
    "        elif metric == 'detection':\n",
    "            return self._create_detection_table()\n",
    "        else:\n",
    "            raise ValueError(\"metric must be 'ARL0', 'ARL1', 'detection', or 'all'\")\n",
    "    \n",
    "    def _create_arl1_table(self) -> pd.DataFrame:\n",
    "        \"\"\"Create ARL1 comparison table with mean and std.\"\"\"\n",
    "        arl1_mean = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='conditional_ARL1'\n",
    "        )\n",
    "        arl1_std = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='SDRL1'\n",
    "        )\n",
    "        \n",
    "        # Combine mean Â± std\n",
    "        combined = pd.DataFrame(index=arl1_mean.index)\n",
    "        for model in arl1_mean.columns:\n",
    "            combined[model] = arl1_mean[model].apply(lambda x: f'{x:.1f}' if pd.notna(x) else 'N/A')\n",
    "            combined[f'{model}_std'] = 'Â±' + arl1_std[model].apply(lambda x: f'{x:.1f}' if pd.notna(x) else 'N/A')\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def _create_arl0_table(self) -> pd.DataFrame:\n",
    "        \"\"\"Create ARL0 comparison table with mean and std.\"\"\"\n",
    "        arl0_mean = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='conditional_ARL0'\n",
    "        )\n",
    "        arl0_std = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='SDRL0'\n",
    "        )\n",
    "        \n",
    "        # Combine mean Â± std\n",
    "        combined = pd.DataFrame(index=arl0_mean.index)\n",
    "        for model in arl0_mean.columns:\n",
    "            combined[model] = arl0_mean[model].apply(lambda x: f'{x:.1f}' if pd.notna(x) else 'N/A')\n",
    "            combined[f'{model}_std'] = 'Â±' + arl0_std[model].apply(lambda x: f'{x:.1f}' if pd.notna(x) else 'N/A')\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def _create_detection_table(self) -> pd.DataFrame:\n",
    "        \"\"\"Create detection performance comparison table.\"\"\"\n",
    "        det_frac = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='avg_detection_fraction'\n",
    "        )\n",
    "        non_det = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='non_detection_fraction'\n",
    "        )\n",
    "        \n",
    "        # Combine detection metrics\n",
    "        combined = pd.DataFrame(index=det_frac.index)\n",
    "        for model in det_frac.columns:\n",
    "            combined[f'{model}_DetRate'] = (det_frac[model] * 100).apply(lambda x: f'{x:.1f}%')\n",
    "            combined[f'{model}_MissRate'] = (non_det[model] * 100).apply(lambda x: f'{x:.1f}%')\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def create_summary_statistics(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create overall summary statistics for each model.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with overall performance metrics\n",
    "        \"\"\"\n",
    "        stats = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            model_data = self.df_results[self.df_results['model'] == model]\n",
    "            model_summary = self.summary_df[self.summary_df['model'] == model]\n",
    "            \n",
    "            stats.append({\n",
    "                'Model': model,\n",
    "                'Mean ARL0': model_data['ARL0'].dropna().mean(),\n",
    "                'Std ARL0': model_data['ARL0'].dropna().std(),\n",
    "                'Mean ARL1': model_data['ARL1'].dropna().mean(),\n",
    "                'Std ARL1': model_data['ARL1'].dropna().std(),\n",
    "                'Overall Detection Rate': model_data['detection_fraction'].mean() * 100,\n",
    "                'False Alarm Rate': (model_data['ARL0'].notna().sum() / len(model_data)) * 100,\n",
    "                'Miss Rate': (model_data['ARL1'].isna().sum() / len(model_data)) * 100,\n",
    "                #'Best Fault Detection': model_summary['conditional_ARL1'].idxmin()[1] if not model_summary['conditional_ARL1'].isna().all() else 'N/A',\n",
    "                #'Worst Fault Detection': model_summary['conditional_ARL1'].idxmax()[1] if not model_summary['conditional_ARL1'].isna().all() else 'N/A'\n",
    "            })\n",
    "        \n",
    "        summary_stats_df = pd.DataFrame(stats)\n",
    "        \n",
    "        # Round numerical columns\n",
    "        numeric_cols = ['Mean ARL0', 'Std ARL0', 'Mean ARL1', 'Std ARL1', \n",
    "                       'Overall Detection Rate', 'False Alarm Rate', 'Miss Rate']\n",
    "        summary_stats_df[numeric_cols] = summary_stats_df[numeric_cols].round(2)\n",
    "        \n",
    "        return summary_stats_df\n",
    "    \n",
    "    def plot_arl_comparison(self, figsize: Tuple[int, int] = (15, 6)) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Create bar plots comparing ARL0 and ARL1 across models and faults.\n",
    "        \n",
    "        Returns:\n",
    "            Matplotlib figure object\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "        \n",
    "        # ARL1 comparison\n",
    "        arl1_pivot = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='conditional_ARL1'\n",
    "        )\n",
    "        arl1_pivot.plot(kind='bar', ax=axes[0], width=0.8)\n",
    "        axes[0].set_title('ARL1 (Detection Delay) Comparison', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Fault Number', fontsize=12)\n",
    "        axes[0].set_ylabel('ARL1 (samples)', fontsize=12)\n",
    "        axes[0].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[0].grid(axis='y', alpha=0.3)\n",
    "        axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "        \n",
    "        # ARL0 comparison\n",
    "        arl0_pivot = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='conditional_ARL0'\n",
    "        )\n",
    "        arl0_pivot.plot(kind='bar', ax=axes[1], width=0.8)\n",
    "        axes[1].set_title('ARL0 (False Alarm) Comparison', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel('Fault Number', fontsize=12)\n",
    "        axes[1].set_ylabel('ARL0 (samples)', fontsize=12)\n",
    "        axes[1].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[1].grid(axis='y', alpha=0.3)\n",
    "        axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_detection_heatmap(self, figsize: Tuple[int, int] = (12, 8)) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Create heatmap of detection rates across models and faults.\n",
    "        \n",
    "        Returns:\n",
    "            Matplotlib figure object\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 1, figsize=figsize)\n",
    "        \n",
    "        # Detection fraction heatmap\n",
    "        det_pivot = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='avg_detection_fraction'\n",
    "        ) * 100  # Convert to percentage\n",
    "        \n",
    "        sns.heatmap(det_pivot.T, annot=True, fmt='.1f', cmap='RdYlGn', \n",
    "                   vmin=0, vmax=100, cbar_kws={'label': 'Detection Rate (%)'},\n",
    "                   ax=axes[0])\n",
    "        axes[0].set_title('Detection Rate Heatmap (Higher is Better)', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Fault Number', fontsize=12)\n",
    "        axes[0].set_ylabel('Model', fontsize=12)\n",
    "        \n",
    "        # ARL1 heatmap (lower is better)\n",
    "        arl1_pivot = self.summary_df.pivot(\n",
    "            index='faultNumber', \n",
    "            columns='model', \n",
    "            values='conditional_ARL1'\n",
    "        )\n",
    "        \n",
    "        sns.heatmap(arl1_pivot.T, annot=True, fmt='.0f', cmap='RdYlGn_r',\n",
    "                   cbar_kws={'label': 'ARL1 (samples)'}, ax=axes[1])\n",
    "        axes[1].set_title('ARL1 Heatmap (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel('Fault Number', fontsize=12)\n",
    "        axes[1].set_ylabel('Model', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_performance_boxplots(self, figsize: Tuple[int, int] = (15, 6)) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Create boxplots showing distribution of ARL metrics across simulations.\n",
    "        \n",
    "        Returns:\n",
    "            Matplotlib figure object\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "        \n",
    "        # ARL1 boxplot\n",
    "        arl1_data = [self.df_results[self.df_results['model'] == model]['ARL1'].dropna() \n",
    "                     for model in self.models]\n",
    "        bp1 = axes[0].boxplot(arl1_data, labels=self.models, patch_artist=True)\n",
    "        axes[0].set_title('ARL1 Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_ylabel('ARL1 (samples)', fontsize=12)\n",
    "        axes[0].set_xlabel('Model', fontsize=12)\n",
    "        axes[0].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # ARL0 boxplot\n",
    "        arl0_data = [self.df_results[self.df_results['model'] == model]['ARL0'].dropna() \n",
    "                     for model in self.models]\n",
    "        bp2 = axes[1].boxplot(arl0_data, labels=self.models, patch_artist=True)\n",
    "        axes[1].set_title('ARL0 Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_ylabel('ARL0 (samples)', fontsize=12)\n",
    "        axes[1].set_xlabel('Model', fontsize=12)\n",
    "        axes[1].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Detection fraction boxplot\n",
    "        det_data = [self.df_results[self.df_results['model'] == model]['detection_fraction'] * 100 \n",
    "                   for model in self.models]\n",
    "        bp3 = axes[2].boxplot(det_data, labels=self.models, patch_artist=True)\n",
    "        axes[2].set_title('Detection Rate Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[2].set_ylabel('Detection Rate (%)', fontsize=12)\n",
    "        axes[2].set_xlabel('Model', fontsize=12)\n",
    "        axes[2].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Color the boxplots\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(self.models)))\n",
    "        for bp, color in zip([bp1, bp2, bp3], [colors, colors, colors]):\n",
    "            for patch, c in zip(bp['boxes'], color):\n",
    "                patch.set_facecolor(c)\n",
    "                patch.set_alpha(0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_fault_specific_comparison(self, fault_number: int, figsize: Tuple[int, int] = (12, 8)) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Create detailed comparison for a specific fault.\n",
    "        \n",
    "        Args:\n",
    "            fault_number: The fault number to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure object\n",
    "        \"\"\"\n",
    "        fault_data = self.df_results[self.df_results['faultNumber'] == fault_number]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "        fig.suptitle(f'Fault {fault_number} - Detailed Comparison', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # ARL1 by simulation run\n",
    "        for model in self.models:\n",
    "            model_data = fault_data[fault_data['model'] == model]\n",
    "            axes[0, 0].plot(model_data['simulationRun'], model_data['ARL1'], \n",
    "                          marker='o', label=model, alpha=0.7)\n",
    "        axes[0, 0].set_title('ARL1 Across Simulation Runs')\n",
    "        axes[0, 0].set_xlabel('Simulation Run')\n",
    "        axes[0, 0].set_ylabel('ARL1')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # ARL0 by simulation run\n",
    "        for model in self.models:\n",
    "            model_data = fault_data[fault_data['model'] == model]\n",
    "            axes[0, 1].plot(model_data['simulationRun'], model_data['ARL0'], \n",
    "                          marker='s', label=model, alpha=0.7)\n",
    "        axes[0, 1].set_title('ARL0 Across Simulation Runs')\n",
    "        axes[0, 1].set_xlabel('Simulation Run')\n",
    "        axes[0, 1].set_ylabel('ARL0')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Detection fraction comparison\n",
    "        det_by_model = fault_data.groupby('model')['detection_fraction'].mean() * 100\n",
    "        bars = axes[1, 0].bar(range(len(self.models)), det_by_model.values)\n",
    "        axes[1, 0].set_xticks(range(len(self.models)))\n",
    "        axes[1, 0].set_xticklabels(self.models)\n",
    "        axes[1, 0].set_title('Average Detection Rate')\n",
    "        axes[1, 0].set_ylabel('Detection Rate (%)')\n",
    "        axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, det_by_model.values):\n",
    "            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                          f'{value:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        # Summary statistics table\n",
    "        axes[1, 1].axis('tight')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        summary_data = []\n",
    "        for model in self.models:\n",
    "            model_data = fault_data[fault_data['model'] == model]\n",
    "            summary_data.append([\n",
    "                model,\n",
    "                f\"{model_data['ARL1'].dropna().mean():.1f}\",\n",
    "                f\"{model_data['ARL0'].dropna().mean():.1f}\",\n",
    "                f\"{model_data['detection_fraction'].mean()*100:.1f}%\"\n",
    "            ])\n",
    "        \n",
    "        table = axes[1, 1].table(cellText=summary_data,\n",
    "                                colLabels=['Model', 'Mean ARL1', 'Mean ARL0', 'Det. Rate'],\n",
    "                                cellLoc='center',\n",
    "                                loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1.2, 1.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def generate_full_report(self, save_path: str = None):\n",
    "        \"\"\"\n",
    "        Generate a complete comparison report with all tables and plots.\n",
    "        \n",
    "        Args:\n",
    "            save_path: Optional path to save the report figures\n",
    "        \"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"MODEL PERFORMANCE COMPARISON REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "        \n",
    "        # 1. Overall Summary Statistics\n",
    "        print(\"1. OVERALL SUMMARY STATISTICS\")\n",
    "        print(\"-\" * 40)\n",
    "        summary_stats = self.create_summary_statistics()\n",
    "        print(summary_stats.to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        # 2. Comprehensive Comparison Table\n",
    "        print(\"2. COMPREHENSIVE COMPARISON TABLE\")\n",
    "        print(\"-\" * 40)\n",
    "        comparison_table = self.create_comparison_table('all')\n",
    "        print(comparison_table.to_string())\n",
    "        print()\n",
    "        \n",
    "        # 3. ARL1 Detailed Table\n",
    "        print(\"3. ARL1 COMPARISON (Mean Â± Std)\")\n",
    "        print(\"-\" * 40)\n",
    "        arl1_table = self._create_arl1_table()\n",
    "        print(arl1_table.to_string())\n",
    "        print()\n",
    "        \n",
    "        # 4. Detection Performance Table\n",
    "        print(\"4. DETECTION PERFORMANCE\")\n",
    "        print(\"-\" * 40)\n",
    "        det_table = self._create_detection_table()\n",
    "        print(det_table.to_string())\n",
    "        print()\n",
    "        \n",
    "        # Generate all plots\n",
    "        fig1 = self.plot_arl_comparison()\n",
    "        fig2 = self.plot_detection_heatmap()\n",
    "        fig3 = self.plot_performance_boxplots()\n",
    "        \n",
    "        if save_path:\n",
    "            fig1.savefig(f\"{save_path}_arl_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "            fig2.savefig(f\"{save_path}_detection_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "            fig3.savefig(f\"{save_path}_performance_boxplots.png\", dpi=300, bbox_inches='tight')\n",
    "            print(f\"Figures saved to {save_path}_*.png\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return summary_stats, comparison_table\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "def analyze_results(df_results: pd.DataFrame, summary_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Main function to run the complete analysis.\n",
    "    \n",
    "    Args:\n",
    "        df_results: Your results DataFrame\n",
    "        summary_df: Your summary DataFrame\n",
    "    \"\"\"\n",
    "    # Initialize analyzer\n",
    "    analyzer = ModelComparisonAnalyzer(df_results, summary_df)\n",
    "    \n",
    "    # Generate full report\n",
    "    summary_stats, comparison_table = analyzer.generate_full_report()\n",
    "    \n",
    "    # Generate fault-specific analysis for selected faults\n",
    "    for fault in [1, 5, 10, 15, 20]:  # Analyze specific faults\n",
    "        if fault in analyzer.fault_numbers:\n",
    "            fig = analyzer.plot_fault_specific_comparison(fault)\n",
    "            plt.show()\n",
    "    \n",
    "    # Return analyzer for further custom analysis if needed\n",
    "    return analyzer\n",
    "\n",
    "# After your main loop, use it like this:\n",
    "analyzer = analyze_results(df_results, summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
