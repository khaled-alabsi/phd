{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# STANDALONE EDA DATA PREPARATION\n",
    "# ====================================================================\n",
    "\n",
    "# Import required packages for comprehensive EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.manifold import TSNE\n",
    "from typing import Optional\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data using pyreadr\n",
    "import pyreadr\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_PATH = \"../../output\"\n",
    "VERSION = \"v2\"\n",
    "SIMULATION_RUN_COLUMN_NAME = \"simulationRun\"\n",
    "TARGET_VARIABLE_COLUMN_NAME = \"faultNumber\"\n",
    "FAULT_INJECTION_STARTING_POINT = 160\n",
    "\n",
    "print(\"=== STANDALONE EDA DATA PREPARATION ===\")\n",
    "print(\"Loading raw data directly for exploratory analysis...\")\n",
    "\n",
    "# Load raw data directly - EDA only needs raw data\n",
    "fault_free_training_dict = pyreadr.read_r(\"../../code/Tennessee Eastman/data/TEP_FaultFree_Training.RData\")\n",
    "faulty_training_dict = pyreadr.read_r(\"../../code/Tennessee Eastman/data/TEP_Faulty_Training.RData\")\n",
    "\n",
    "# Extract dataframes from the loaded data\n",
    "faulty_key = list(faulty_training_dict.keys())[0]\n",
    "faultfree_key = list(fault_free_training_dict.keys())[0]\n",
    "\n",
    "DF_F_TRAINING_RAW = faulty_training_dict[faulty_key]\n",
    "DF_FF_TRAINING_RAW = fault_free_training_dict[faultfree_key]\n",
    "\n",
    "print(\"✓ Raw data loaded successfully!\")\n",
    "print(f\"✓ Faulty training data shape: {DF_F_TRAINING_RAW.shape}\")\n",
    "print(f\"✓ Fault-free training data shape: {DF_FF_TRAINING_RAW.shape}\")\n",
    "print(f\"✓ Available columns: {list(DF_F_TRAINING_RAW.columns[:10])}...\")  # Show first 10 columns\n",
    "print(f\"✓ Unique fault numbers: {sorted(DF_F_TRAINING_RAW[TARGET_VARIABLE_COLUMN_NAME].unique())}\")\n",
    "print(\"=== EDA DATA PREPARATION COMPLETE ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78576b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VERSION = \"1.00\"\n",
    "OUTPUT_PATH = \"output\"\n",
    "TARGET_VARIABLE_COLUMN_NAME = \"faultNumber\"\n",
    "SIMULATION_RUN_COLUMN_NAME = \"simulationRun\"\n",
    "COLUMNS_TO_REMOVE = [\"simulationRun\", \"sample\"]\n",
    "SKIPED_FAULTS = []\n",
    "FAULTS_TO_BE_MERGED_TOGETHER = [3, 8, 9, 18, 15]\n",
    "MERGE_FAUTS_TO_NUMBER = 3\n",
    "FAULT_INJECTION_STARTING_POINT = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4391e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(plot_name: str,\n",
    "              suffix: str = \"\",\n",
    "              plot_path: str = \"EDA\") -> None:\n",
    "    \"\"\"Save current matplotlib figure.\"\"\"\n",
    "    timestamp: str = \"\"\n",
    "    base_dir: str = os.path.join(OUTPUT_PATH, \"data\", plot_path)\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename: str = f\"{plot_name}_{suffix}_v{VERSION}_{timestamp}.png\" if suffix else f\"{plot_name}_v{VERSION}_{timestamp}.png\"\n",
    "    filepath: str = os.path.join(base_dir, filename)\n",
    "\n",
    "    plt.savefig(filepath, bbox_inches=\"tight\", dpi=300)\n",
    "    print(f\"Plot saved: {filepath}\")\n",
    "\n",
    "\n",
    "def save_dataframe(df: pd.DataFrame, name: str, suffix: str = \"\") -> None:\n",
    "    \"\"\"Save a DataFrame to CSV.\"\"\"\n",
    "    timestamp: str = \"\"\n",
    "    base_dir: str = os.path.join(OUTPUT_PATH, \"data\")\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename: str = f\"{name}_{suffix}_v{VERSION}_{timestamp}.csv\" if suffix else f\"{name}_v{VERSION}_{timestamp}.csv\"\n",
    "    filepath: str = os.path.join(base_dir, filename)\n",
    "\n",
    "    df.to_csv(filepath, index=True)\n",
    "    print(f\"Data saved: {filepath}\")\n",
    "\n",
    "\n",
    "def save_pickle(obj, name: str, suffix: str = \"\") -> None:\n",
    "    \"\"\"Save object as pickle file.\"\"\"\n",
    "    timestamp: str = \"\"\n",
    "    base_dir: str = os.path.join(OUTPUT_PATH, \"data\")\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename: str = f\"{name}_{suffix}_v{VERSION}_{timestamp}.pkl\" if suffix else f\"{name}_v{VERSION}_{timestamp}.pkl\"\n",
    "    filepath: str = os.path.join(base_dir, filename)\n",
    "\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"Results saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics_per_fault_run(\n",
    "        df_faulty: pd.DataFrame, df_normal: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive statistics for each fault run including mean, std, skewness, kurtosis, and autocorrelation.\n",
    "    \"\"\"\n",
    "    base_dir: str = os.path.join(OUTPUT_PATH, \"data\", \"fault_statistics.csv\")\n",
    "    output_path: Path = Path(base_dir)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if output_path.exists():\n",
    "        return pd.read_csv(output_path)\n",
    "\n",
    "    features: list[str] = [\n",
    "        col for col in df_faulty.columns\n",
    "        if col not in [TARGET_VARIABLE_COLUMN_NAME, SIMULATION_RUN_COLUMN_NAME, \"time\", \"sample\"]\n",
    "    ]\n",
    "\n",
    "    def compute_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        rows: list[dict] = []\n",
    "        grouped = df.groupby([TARGET_VARIABLE_COLUMN_NAME, SIMULATION_RUN_COLUMN_NAME])\n",
    "        for (fault, run), group in grouped:\n",
    "            for feature in features:\n",
    "                values: pd.Series = group[feature].dropna()\n",
    "                if values.empty:\n",
    "                    continue\n",
    "                rows.append({\n",
    "                    TARGET_VARIABLE_COLUMN_NAME: fault,\n",
    "                    SIMULATION_RUN_COLUMN_NAME: run,\n",
    "                    \"feature\": feature,\n",
    "                    \"mean\": values.mean(),\n",
    "                    \"std\": values.std(),\n",
    "                    \"skewness\": skew(values),\n",
    "                    \"kurtosis\": kurtosis(values),\n",
    "                    \"autocorr_1\": values.autocorr(lag=1) if len(values) > 1 else np.nan,\n",
    "                })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    df_all: pd.DataFrame = pd.concat([df_normal, df_faulty], ignore_index=True)\n",
    "    result_df: pd.DataFrame = compute_stats(df_all)\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    save_dataframe(df=result_df, name=\"fault_statistics\")\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def calculate_statistics_per_fault_run(\n",
    "        df_faulty: pd.DataFrame, df_normal: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculate comprehensive statistics per fault and simulation run.\"\"\"\n",
    "    features: list[str] = [\n",
    "        col for col in df_faulty.columns if col not in [\n",
    "            TARGET_VARIABLE_COLUMN_NAME, SIMULATION_RUN_COLUMN_NAME, \"time\",\n",
    "            \"sample\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    def compute_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        rows: list[dict] = []\n",
    "        grouped = df.groupby(\n",
    "            [TARGET_VARIABLE_COLUMN_NAME, SIMULATION_RUN_COLUMN_NAME])\n",
    "\n",
    "        for (fault, run), group in grouped:\n",
    "            for feature in features:\n",
    "                values: pd.Series = group[feature].dropna()\n",
    "                if values.empty:\n",
    "                    continue\n",
    "\n",
    "                rows.append({\n",
    "                    TARGET_VARIABLE_COLUMN_NAME:\n",
    "                    fault,\n",
    "                    SIMULATION_RUN_COLUMN_NAME:\n",
    "                    run,\n",
    "                    \"feature\":\n",
    "                    feature,\n",
    "                    \"mean\":\n",
    "                    values.mean(),\n",
    "                    \"std\":\n",
    "                    values.std(),\n",
    "                    \"skewness\":\n",
    "                    skew(values),\n",
    "                    \"kurtosis\":\n",
    "                    kurtosis(values),\n",
    "                    \"autocorr_1\":\n",
    "                    values.autocorr(lag=1) if len(values) > 1 else np.nan,\n",
    "                })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    df_all: pd.DataFrame = pd.concat([df_normal, df_faulty], ignore_index=True)\n",
    "    result_df: pd.DataFrame = compute_stats(df_all)\n",
    "\n",
    "    save_dataframe(df=result_df, name=\"fault_statistics\", suffix=\"EDA\")\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Calculate statistics for reduced dataset\n",
    "statics_f_df = DF_F_TRAINING_RAW[\n",
    "    (DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] >= 1)\n",
    "    & (DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] < 4)]\n",
    "statics_ff_df = DF_FF_TRAINING_RAW[\n",
    "    (DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] >= 1)\n",
    "    & (DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] < 4)]\n",
    "\n",
    "stats_df = calculate_statistics_per_fault_run(df_faulty=statics_f_df,\n",
    "                                              df_normal=statics_ff_df)\n",
    "print(\n",
    "    f\"Statistics calculated for {len(stats_df)} feature-fault-run combinations\"\n",
    ")\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_boxplots(df_fault: pd.DataFrame, df_normal: pd.DataFrame, \n",
    "                                fault_number: int = 3, simulation_run: int = 10, \n",
    "                                plot_type: str = \"normal\"):\n",
    "    \"\"\"\n",
    "    Create comprehensive boxplots for all features comparing fault vs normal data.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_fault: Faulty data\n",
    "    - df_normal: Normal data  \n",
    "    - fault_number: Which fault to analyze\n",
    "    - simulation_run: Which simulation run to use\n",
    "    - plot_type: \"normal\", \"fault\", or \"combined\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if plot_type == \"fault\":\n",
    "        df_selected_f_data = df_fault[\n",
    "            (df_fault[TARGET_VARIABLE_COLUMN_NAME] == fault_number)\n",
    "            & (df_fault[SIMULATION_RUN_COLUMN_NAME] == simulation_run)]\n",
    "        used_data = df_selected_f_data\n",
    "        title_suffix = f\"Fault {fault_number}\"\n",
    "    elif plot_type == \"normal\":\n",
    "        df_select_ff_data = df_normal[\n",
    "            (df_normal[TARGET_VARIABLE_COLUMN_NAME] == 0)\n",
    "            & (df_normal[SIMULATION_RUN_COLUMN_NAME] == simulation_run)]\n",
    "        used_data = df_select_ff_data\n",
    "        title_suffix = \"Normal Operation\"\n",
    "    else:  # combined\n",
    "        # This will be handled separately for side-by-side comparison\n",
    "        pass\n",
    "\n",
    "    if plot_type != \"combined\":\n",
    "        feature_columns = df_normal.columns[3:]\n",
    "        num_features = len(feature_columns)\n",
    "\n",
    "        # Define the number of rows and columns for the subplots in the grid\n",
    "        num_cols = min(4, num_features)  # Maximum of 4 columns\n",
    "        num_rows = int(np.ceil(num_features / num_cols))\n",
    "        fig, axes = plt.subplots(num_rows,\n",
    "                                 num_cols,\n",
    "                                 figsize=(4 * num_cols, 3 * num_rows))\n",
    "        fig.suptitle(f\"Boxplots of All Features - {title_suffix}\", fontsize=16, y=1.02)\n",
    "\n",
    "        for i, col in enumerate(feature_columns):\n",
    "            row_index = i // num_cols\n",
    "            col_index = i % num_cols\n",
    "            if num_rows == 1:\n",
    "                ax = axes[col_index] if num_cols > 1 else axes\n",
    "            else:\n",
    "                ax = axes[row_index, col_index] if num_cols > 1 else axes[row_index]\n",
    "\n",
    "            ax.boxplot(\n",
    "                used_data[col],\n",
    "                patch_artist=True,\n",
    "                boxprops=dict(facecolor=\"lightblue\", color=\"navy\"),\n",
    "                medianprops=dict(color=\"red\"),\n",
    "                whiskerprops=dict(color=\"gray\"),\n",
    "                capprops=dict(color=\"gray\"),\n",
    "                flierprops=dict(marker=\"o\", color=\"darkorange\", alpha=0.5),\n",
    "            )\n",
    "\n",
    "            ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "            ax.set_ylabel(col)\n",
    "            ax.set_title(col.replace(\"_\", \" \"))\n",
    "\n",
    "        # Remove empty subplots\n",
    "        for i in range(num_features, num_rows * num_cols):\n",
    "            if num_rows > 1 and num_cols > 1:\n",
    "                fig.delaxes(axes.flatten()[i])\n",
    "            elif num_rows == 1 and num_cols > 1:\n",
    "                fig.delaxes(axes[i])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_plot(f\"boxplots_all_features_{title_suffix.lower().replace(' ', '_')}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b09c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distribution_plots(df_fault: pd.DataFrame, df_normal: pd.DataFrame,\n",
    "                             fault_number: int = 3, simulation_run: int = 1,\n",
    "                             max_features: int = 10):\n",
    "    \"\"\"\n",
    "    Create side-by-side distribution plots comparing fault vs normal data.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_fault: Faulty data\n",
    "    - df_normal: Normal data\n",
    "    - fault_number: Which fault to analyze\n",
    "    - simulation_run: Which simulation run to use\n",
    "    - max_features: Maximum number of features to plot (to avoid overcrowding)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_selected_f_data = df_fault[\n",
    "        (df_fault[TARGET_VARIABLE_COLUMN_NAME] == fault_number)\n",
    "        & (df_fault[SIMULATION_RUN_COLUMN_NAME] == simulation_run)]\n",
    "    df_select_ff_data = df_normal[\n",
    "        (df_normal[TARGET_VARIABLE_COLUMN_NAME] == 0)\n",
    "        & (df_normal[SIMULATION_RUN_COLUMN_NAME] == simulation_run)]\n",
    "\n",
    "    # Select features to plot (limit to max_features for readability)\n",
    "    selected_features = df_selected_f_data.columns[3:3+max_features]\n",
    "    \n",
    "    # Create a figure with subplots for each selected feature\n",
    "    fig, axes = plt.subplots(len(selected_features), 2, \n",
    "                            figsize=(12, 6 * len(selected_features)))\n",
    "    \n",
    "    for i, feature in enumerate(selected_features):\n",
    "        # Plotting the faulty data distribution\n",
    "        sns.histplot(\n",
    "            df_selected_f_data[feature],\n",
    "            kde=True,\n",
    "            ax=axes[i, 0],\n",
    "            color=\"red\",\n",
    "            label=\"Faulty Data\",\n",
    "        )\n",
    "        axes[i, 0].set_title(f\"Faulty Data - {feature}\")\n",
    "        axes[i, 0].set_xlabel(feature)\n",
    "        axes[i, 0].set_ylabel(\"Density\")\n",
    "        axes[i, 0].legend()\n",
    "        \n",
    "        # Plotting the fault-free data distribution\n",
    "        sns.histplot(\n",
    "            df_select_ff_data[feature],\n",
    "            kde=True,\n",
    "            ax=axes[i, 1],\n",
    "            color=\"blue\",\n",
    "            label=\"Fault-Free Data\",\n",
    "        )\n",
    "        axes[i, 1].set_title(f\"Fault-Free Data - {feature}\")\n",
    "        axes[i, 1].set_xlabel(feature)\n",
    "        axes[i, 1].set_ylabel(\"Density\")\n",
    "        axes[i, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_plot(f\"distribution_comparison_fault_{fault_number}_run_{simulation_run}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_visualization(x_data: np.ndarray, y_labels: np.ndarray, \n",
    "                           step: int = 50, title: str = \"t-SNE Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualize class separation and structure in high-dimensional process data using t-SNE embedding to 2D.\n",
    "\n",
    "    Parameters:\n",
    "    - x_data: High-dimensional feature matrix (e.g., 54 dimensions).\n",
    "    - y_labels: 1D label array corresponding to x_data.\n",
    "    - step: Downsampling factor to reduce computational load (default=50).\n",
    "    - title: Plot title\n",
    "    \"\"\"\n",
    "\n",
    "    # Downsample the data to reduce computation\n",
    "    x_down = x_data[::step, :]\n",
    "    y_label = y_labels[::step]\n",
    "\n",
    "    print(f\"Applying t-SNE to {x_down.shape[0]} samples with {x_down.shape[1]} features...\")\n",
    "    \n",
    "    # Apply t-SNE to project high-dimensional data into 2D space\n",
    "    x_embedded = TSNE(n_components=2, learning_rate=\"auto\",\n",
    "                      init=\"random\", random_state=42).fit_transform(x_down)\n",
    "\n",
    "    # Create a scatter plot of the 2D embedded data\n",
    "    f, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.scatterplot(\n",
    "        x=x_embedded[:, 0],\n",
    "        y=x_embedded[:, 1],\n",
    "        hue=y_label,\n",
    "        style=y_label,\n",
    "        palette=\"bright\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"t-SNE Component 1\")\n",
    "    plt.ylabel(\"t-SNE Component 2\")\n",
    "    save_plot(\"tsne_visualization\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adbb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fault_injection_segment(\n",
    "    df: pd.DataFrame,\n",
    "    fault_injection_index: int,\n",
    "    features: list[str],\n",
    "    fault_number: int,\n",
    "    point_start: int = 0,\n",
    "    point_end: int = 500,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot feature time series before and after fault injection.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing time series (1 simulation run).\n",
    "    - fault_injection_index: Time step where fault is injected.\n",
    "    - features: List of feature names to plot.\n",
    "    - fault_number: Fault number to analyze\n",
    "    - point_start: Starting time point\n",
    "    - point_end: Ending time point\n",
    "    \"\"\"\n",
    "    # Filter only the rows with the selected fault number\n",
    "    df_filtered = df[df[TARGET_VARIABLE_COLUMN_NAME] == fault_number].reset_index(drop=True)\n",
    "\n",
    "    x_range = np.arange(point_start, point_end)\n",
    "    df_window = df_filtered.iloc[point_start:point_end]\n",
    "\n",
    "    n_features = len(features)\n",
    "    fig, axes = plt.subplots(n_features, 1, figsize=(15, 3 * n_features), sharex=True)\n",
    "\n",
    "    if n_features == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "        y = df_window[feature].values\n",
    "        ax.plot(x_range, y, label=feature, color=\"black\")\n",
    "\n",
    "        # Mark every 20th time index for readability\n",
    "        for x in x_range:\n",
    "            if x % 20 == 0:\n",
    "                ax.axvline(x, color=\"gray\", linestyle=\":\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # Vertical fault injection marker\n",
    "        ax.axvline(\n",
    "            fault_injection_index,\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            label=\"Fault Injected\",\n",
    "        )\n",
    "\n",
    "        # Text showing the fault injection point\n",
    "        ax.text(\n",
    "            fault_injection_index,\n",
    "            ax.get_ylim()[1] * 0.9,\n",
    "            f\"Fault Injection\\nt={fault_injection_index}\",\n",
    "            color=\"red\",\n",
    "            fontsize=10,\n",
    "            ha=\"center\",\n",
    "            va=\"top\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
    "        )\n",
    "\n",
    "        # Calculate median before/after\n",
    "        before = df_filtered.loc[point_start:fault_injection_index - 1, feature]\n",
    "        after = df_filtered.loc[fault_injection_index:point_end - 1, feature]\n",
    "\n",
    "        if len(before) > 0 and len(after) > 0:\n",
    "            before_med = np.median(before)\n",
    "            after_med = np.median(after)\n",
    "\n",
    "            ax.axhline(before_med, color=\"blue\", linestyle=\":\", alpha=0.7, label=\"Median Before\")\n",
    "            ax.axhline(after_med, color=\"green\", linestyle=\":\", alpha=0.7, label=\"Median After\")\n",
    "\n",
    "        ax.set_ylabel(feature)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.legend(loc=\"best\")\n",
    "\n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.suptitle(f\"Feature Response Around Fault {fault_number} Injection\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    save_plot(f\"fault_injection_analysis_fault_{fault_number}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_boxplots_all_features(df, title_suffix=\"\"):\n",
    "    \"\"\"Plot boxplots for all features.\"\"\"\n",
    "    feature_columns = df.columns[3:] if len(df.columns) > 3 else df.columns\n",
    "    num_features = len(feature_columns)\n",
    "\n",
    "    num_cols = min(4, num_features)\n",
    "    num_rows = int(np.ceil(num_features / num_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows,\n",
    "                             num_cols,\n",
    "                             figsize=(4 * num_cols, 3 * num_rows))\n",
    "    fig.suptitle(f\"Boxplots of All Features {title_suffix}\",\n",
    "                 fontsize=16,\n",
    "                 y=1.02)\n",
    "\n",
    "    for i, col in enumerate(feature_columns):\n",
    "        row_index = i // num_cols\n",
    "        col_index = i % num_cols\n",
    "\n",
    "        if num_rows == 1:\n",
    "            ax = axes[col_index] if num_cols > 1 else axes\n",
    "        else:\n",
    "            ax = axes[row_index,\n",
    "                      col_index] if num_cols > 1 else axes[row_index]\n",
    "\n",
    "        ax.boxplot(\n",
    "            df[col],\n",
    "            patch_artist=True,\n",
    "            boxprops=dict(facecolor=\"lightblue\", color=\"navy\"),\n",
    "            medianprops=dict(color=\"red\"),\n",
    "            whiskerprops=dict(color=\"gray\"),\n",
    "            capprops=dict(color=\"gray\"),\n",
    "            flierprops=dict(marker=\"o\", color=\"darkorange\", alpha=0.5),\n",
    "        )\n",
    "\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "        ax.set_ylabel(col)\n",
    "        ax.set_title(col.replace(\"_\", \" \"))\n",
    "\n",
    "    # Remove empty subplots\n",
    "    if num_rows > 1 and num_cols > 1:\n",
    "        for i in range(num_features, num_rows * num_cols):\n",
    "            fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_plot(\"boxplots_all_features\", title_suffix.replace(\" \", \"_\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07589a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fault_vs_normal_segment(\n",
    "    df_fault: pd.DataFrame,\n",
    "    df_normal: pd.DataFrame,\n",
    "    features: list[str],\n",
    "    point_start: int,\n",
    "    point_end: int,\n",
    "    fault_number: int,\n",
    "    fault_injection_index: int = 160,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Compare fault vs normal time series for selected features.\n",
    "\n",
    "    Parameters:\n",
    "    - df_fault: DataFrame with faults (should include faultNumber column).\n",
    "    - df_normal: Normal (non-faulty) baseline DataFrame.\n",
    "    - features: List of feature names to compare.\n",
    "    - point_start: Start index of window.\n",
    "    - point_end: End index of window (exclusive).\n",
    "    - fault_number: Fault number to extract from df_fault.\n",
    "    - fault_injection_index: When the fault was injected\n",
    "    \"\"\"\n",
    "    df_fault_filtered = df_fault[df_fault[TARGET_VARIABLE_COLUMN_NAME] == fault_number].reset_index(drop=True)\n",
    "    df_fault_window = df_fault_filtered.iloc[point_start:point_end]\n",
    "    df_normal_window = df_normal.iloc[point_start:point_end]\n",
    "\n",
    "    x_range = np.arange(point_start, point_end)\n",
    "    n_features = len(features)\n",
    "    fig, axes = plt.subplots(n_features, 1, figsize=(15, 3 * n_features), sharex=True)\n",
    "\n",
    "    if n_features == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "\n",
    "        y_fault = df_fault_window[feature].values\n",
    "        y_normal = df_normal_window[feature].values\n",
    "\n",
    "        ax.plot(x_range, y_fault, label=f\"Fault {fault_number}\", color=\"red\", linewidth=2)\n",
    "        ax.plot(x_range, y_normal, label=\"Normal\", color=\"blue\", linewidth=2)\n",
    "\n",
    "        # Median lines\n",
    "        ax.axhline(\n",
    "            np.median(y_normal),\n",
    "            color=\"blue\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.7,\n",
    "            label=\"Normal Median\",\n",
    "        )\n",
    "        ax.axhline(\n",
    "            np.median(y_fault),\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.7,\n",
    "            label=\"Fault Median\",\n",
    "        )\n",
    "        \n",
    "        # Fault injection marker\n",
    "        if point_start <= fault_injection_index <= point_end:\n",
    "            ax.axvline(\n",
    "                fault_injection_index,\n",
    "                color=\"green\",\n",
    "                linestyle=\"-\",\n",
    "                linewidth=3,\n",
    "                alpha=0.8,\n",
    "                label=\"Fault Injected\",\n",
    "            )\n",
    "\n",
    "        # Mark every 10th index for reference\n",
    "        for x in x_range:\n",
    "            if x % 10 == 0:\n",
    "                ax.axvline(x, color=\"gray\", linestyle=\":\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "        ax.set_ylabel(feature)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.legend(loc=\"best\")\n",
    "\n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.suptitle(f\"Fault {fault_number} vs Normal Comparison\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    save_plot(f\"fault_vs_normal_comparison_fault_{fault_number}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_faults_stat(\n",
    "    stats_df: pd.DataFrame,\n",
    "    fault_a: int,\n",
    "    fault_b: int,\n",
    "    run_id: int,\n",
    "    stat: str = \"mean\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare statistical measures between two faults for a specific run.\n",
    "    \"\"\"\n",
    "    df_a = stats_df.query(\n",
    "        \"faultNumber == @fault_a and simulationRun == @run_id\")[[\n",
    "            \"feature\", stat\n",
    "        ]].rename(columns={stat: f\"fault_{fault_a}\"})\n",
    "\n",
    "    df_b = stats_df.query(\n",
    "        \"faultNumber == @fault_b and simulationRun == @run_id\")[[\n",
    "            \"feature\", stat\n",
    "        ]].rename(columns={stat: f\"fault_{fault_b}\"})\n",
    "\n",
    "    merged = pd.merge(df_a, df_b, on=\"feature\", how=\"outer\")\n",
    "    merged[\"delta\"] = merged[f\"fault_{fault_a}\"] - merged[f\"fault_{fault_b}\"]\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15eb00",
   "metadata": {},
   "source": [
    "# Comprehensive Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "**The TEP variables (columns 4 to 55) were sampled every 3 minutes for a total duration of 25 hours and 48 hours respectively.\n",
    "The faults were introduced 1 hour into the Faulty Training and 8 hours into Faulty Testing datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Faulty training data shape: {DF_F_TRAINING_RAW.shape}\")\n",
    "print(f\"Fault-free training data shape: {DF_FF_TRAINING_RAW.shape}\")\n",
    "print(f\"\\nColumn names: {list(DF_F_TRAINING_RAW.columns[:10])}...\")  # Show first 10 columns\n",
    "\n",
    "print(f\"\\nUnique fault numbers in faulty data: {sorted(DF_F_TRAINING_RAW[TARGET_VARIABLE_COLUMN_NAME].unique())}\")\n",
    "print(f\"Unique simulation runs in faulty data: {sorted(DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME].unique())}\")\n",
    "\n",
    "print(f\"\\nFault-free data fault numbers: {sorted(DF_FF_TRAINING_RAW[TARGET_VARIABLE_COLUMN_NAME].unique())}\")\n",
    "print(f\"Fault-free simulation runs: {sorted(DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME].unique())}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n=== FIRST FEW ROWS OF FAULTY DATA ===\")\n",
    "display(DF_F_TRAINING_RAW.head())\n",
    "\n",
    "print(\"\\n=== FIRST FEW ROWS OF FAULT-FREE DATA ===\")\n",
    "display(DF_FF_TRAINING_RAW.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3261e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive statistics per fault run\n",
    "# Using reduced data for speed (first 3 simulation runs)\n",
    "print(\"=== CALCULATING COMPREHENSIVE STATISTICS ===\")\n",
    "statics_f_df = DF_F_TRAINING_RAW[(DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] >= 1)\n",
    "                             & (DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] < 4)]\n",
    "statics_ff_df = DF_FF_TRAINING_RAW[(DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] >= 1)\n",
    "                               & (DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] < 4)]\n",
    "\n",
    "print(f\"Reduced faulty data shape: {statics_f_df.shape}\")\n",
    "print(f\"Reduced fault-free data shape: {statics_ff_df.shape}\")\n",
    "\n",
    "# Calculate statistics\n",
    "stats_df = calculate_statistics_per_fault_run(df_faulty=statics_f_df,\n",
    "                                              df_normal=statics_ff_df)\n",
    "\n",
    "print(f\"\\nStatistics dataframe shape: {stats_df.shape}\")\n",
    "print(\"Sample of calculated statistics:\")\n",
    "display(stats_df.head(10))\n",
    "\n",
    "# Save the statistics\n",
    "#save_dataframe(stats_df, \"comprehensive_fault_statistics\")\n",
    "\n",
    "# Show statistics for a specific fault\n",
    "print(\"\\n=== STATISTICS FOR FAULT 3, RUN 1 ===\")\n",
    "display(stats_df.query(\"faultNumber == 3 and simulationRun == 1\").head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175b45d",
   "metadata": {},
   "source": [
    "## Boxplot Analysis\n",
    "\n",
    "Comparing the distribution of features between normal and faulty operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots for normal operation\n",
    "print(\"Creating boxplots for normal operation...\")\n",
    "create_comprehensive_boxplots(DF_F_TRAINING_RAW, DF_FF_TRAINING_RAW, \n",
    "                             fault_number=3, simulation_run=10, plot_type=\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots for fault 3\n",
    "print(\"Creating boxplots for fault 3...\")\n",
    "create_comprehensive_boxplots(DF_F_TRAINING_RAW, DF_FF_TRAINING_RAW, \n",
    "                             fault_number=3, simulation_run=10, plot_type=\"fault\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3669bf",
   "metadata": {},
   "source": [
    "## Distribution Analysis\n",
    "\n",
    "Comparing the distribution patterns between fault and fault-free data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plots comparing fault vs normal\n",
    "print(\"Creating distribution plots for fault 3 vs normal...\")\n",
    "create_distribution_plots(DF_F_TRAINING_RAW, DF_FF_TRAINING_RAW,\n",
    "                         fault_number=3, simulation_run=1, max_features=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea4e4b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the Tennessee Eastman Process dataset. This notebook is completely standalone and loads raw data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb405a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pickle\n",
    "import os\n",
    "import pyreadr\n",
    "from pathlib import Path\n",
    "from ipywidgets import Button, HBox, VBox, Output, Dropdown\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Union, List, Tuple\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db781a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VERSION = \"1.00\"\n",
    "OUTPUT_PATH = \"output\"\n",
    "TARGET_VARIABLE_COLUMN_NAME = \"faultNumber\"\n",
    "SIMULATION_RUN_COLUMN_NAME = \"simulationRun\"\n",
    "COLUMNS_TO_REMOVE = [\"simulationRun\", \"sample\"]\n",
    "SKIPED_FAULTS = []\n",
    "FAULTS_TO_BE_MERGED_TOGETHER = [3, 8, 9, 18, 15]\n",
    "MERGE_FAUTS_TO_NUMBER = 3\n",
    "FAULT_INJECTION_STARTING_POINT = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae096173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dddd86a8",
   "metadata": {},
   "source": [
    "## Load Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02642770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data is already loaded above in the EDA data preparation section\n",
    "# # Use the raw data that was loaded earlier\n",
    "\n",
    "# print(f\"Raw fault-free training shape: {DF_FF_TRAINING_RAW.shape}\")\n",
    "# print(f\"Raw faulty training shape: {DF_F_TRAINING_RAW.shape}\")\n",
    "\n",
    "# # Create a simple combined dataset for EDA analysis\n",
    "# print(\"Preparing data for EDA analysis...\")\n",
    "\n",
    "# # Select only a subset for EDA to speed up processing\n",
    "# feature_cols = [col for col in DF_F_TRAINING_RAW.columns \n",
    "#                 if col not in [TARGET_VARIABLE_COLUMN_NAME, SIMULATION_RUN_COLUMN_NAME, \"sample\"]]\n",
    "\n",
    "# # Use limited simulation runs for EDA\n",
    "# X_TRAIN = DF_F_TRAINING_RAW[(DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] >= 1) & \n",
    "#                            (DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] < 3)][feature_cols].to_numpy()\n",
    "# Y_TRAIN_DF = DF_F_TRAINING_RAW[(DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] >= 1) & \n",
    "#                                (DF_F_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] < 3)][TARGET_VARIABLE_COLUMN_NAME]\n",
    "\n",
    "# print(f\"EDA analysis features shape: {X_TRAIN.shape}\")\n",
    "# print(f\"EDA analysis labels shape: {Y_TRAIN_DF.shape}\")\n",
    "# print(\"✓ Data prepared for EDA analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12dcdcc",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c7bec",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9b925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_comparison(df_faulty, df_normal, fault_number=3, simulation_run=1):\n",
    "    \"\"\"Plot distribution comparison between faulty and normal data.\"\"\"\n",
    "    df_selected_f_data = df_faulty[\n",
    "        (df_faulty[TARGET_VARIABLE_COLUMN_NAME] == fault_number) &\n",
    "        (df_faulty[SIMULATION_RUN_COLUMN_NAME] == simulation_run)\n",
    "    ]\n",
    "    df_select_ff_data = df_normal[\n",
    "        (df_normal[TARGET_VARIABLE_COLUMN_NAME] == 0) &\n",
    "        (df_normal[SIMULATION_RUN_COLUMN_NAME] == simulation_run)\n",
    "    ]\n",
    "\n",
    "    selected_features = df_selected_f_data.columns[3:8]  # Select first 5 features for demo\n",
    "    \n",
    "    fig, axes = plt.subplots(len(selected_features), 2, figsize=(12, 6 * len(selected_features)))\n",
    "    \n",
    "    for i, feature in enumerate(selected_features):\n",
    "        # Faulty data\n",
    "        sns.histplot(\n",
    "            df_selected_f_data[feature],\n",
    "            kde=True,\n",
    "            ax=axes[i, 0],\n",
    "            color=\"red\",\n",
    "            label=\"Faulty Data\",\n",
    "        )\n",
    "        axes[i, 0].set_title(f\"Faulty Data - {feature}\")\n",
    "        axes[i, 0].set_xlabel(feature)\n",
    "        axes[i, 0].set_ylabel(\"Density\")\n",
    "        axes[i, 0].legend()\n",
    "        \n",
    "        # Normal data\n",
    "        sns.histplot(\n",
    "            df_select_ff_data[feature],\n",
    "            kde=True,\n",
    "            ax=axes[i, 1],\n",
    "            color=\"blue\",\n",
    "            label=\"Fault-Free Data\",\n",
    "        )\n",
    "        axes[i, 1].set_title(f\"Fault-Free Data - {feature}\")\n",
    "        axes[i, 1].set_xlabel(feature)\n",
    "        axes[i, 1].set_ylabel(\"Density\")\n",
    "        axes[i, 1].legend()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    save_plot(\"distribution_comparison\", f\"fault_{fault_number}_run_{simulation_run}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d65f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_visualization(x_train: np.ndarray, y_labeled_train: np.ndarray, step: int = 50) -> None:\n",
    "    \"\"\"Visualize class separation using t-SNE.\"\"\"\n",
    "    # Downsample for computation\n",
    "    x_down = x_train[::step, :]\n",
    "    y_label = y_labeled_train[::step]\n",
    "\n",
    "    # Apply t-SNE\n",
    "    x_embedded = TSNE(n_components=2, learning_rate=\"auto\", init=\"random\", random_state=42).fit_transform(x_down)\n",
    "\n",
    "    # Plot\n",
    "    f, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        x=x_embedded[:, 0],\n",
    "        y=x_embedded[:, 1],\n",
    "        hue=y_label,\n",
    "        style=y_label,\n",
    "        palette=\"bright\",\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.title(\"t-SNE Visualization of Labeled Data\")\n",
    "    save_plot(\"tsne_visualization\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7106b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df, threshold: float = 0.95):\n",
    "    \"\"\"Plot correlation matrix with threshold filtering.\"\"\"\n",
    "    data = df[df[SIMULATION_RUN_COLUMN_NAME] == 1].iloc[:, 3:] if SIMULATION_RUN_COLUMN_NAME in df.columns else df\n",
    "    corr = data.corr()\n",
    "\n",
    "    if threshold < 1.0:\n",
    "        # Filter high correlations\n",
    "        corr_abs = corr.abs().copy()\n",
    "        np.fill_diagonal(corr_abs.values, 0.0)\n",
    "        \n",
    "        selected_features = set(corr_abs.columns[(corr_abs > threshold).any()])\n",
    "        selected_features_list = sorted(selected_features)\n",
    "        \n",
    "        if selected_features_list:\n",
    "            filtered_corr = corr.loc[selected_features_list, selected_features_list]\n",
    "            mask = np.triu(np.ones_like(filtered_corr, dtype=bool))\n",
    "            \n",
    "            f, ax = plt.subplots(figsize=(12, 10))\n",
    "            sns.heatmap(\n",
    "                filtered_corr,\n",
    "                mask=mask,\n",
    "                cmap=\"coolwarm\",\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.5},\n",
    "            )\n",
    "            plt.title(f\"Correlation Matrix (|corr| > {threshold})\")\n",
    "            save_plot(\"correlation_matrix\", f\"threshold_{threshold}\")\n",
    "        else:\n",
    "            print(f\"No correlations above threshold {threshold} found.\")\n",
    "    else:\n",
    "        # Full correlation matrix\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "        f, ax = plt.subplots(figsize=(20, 20))\n",
    "        sns.heatmap(\n",
    "            corr,\n",
    "            mask=mask,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.5},\n",
    "        )\n",
    "        plt.title(\"Full Correlation Matrix\")\n",
    "        save_plot(\"correlation_matrix\", \"full\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daac9a5",
   "metadata": {},
   "source": [
    "## Generate EDA Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Boxplots for fault-free data\n",
    "fault_free_sample = DF_FF_TRAINING_RAW[\n",
    "    (DF_FF_TRAINING_RAW[TARGET_VARIABLE_COLUMN_NAME] == 0) &\n",
    "    (DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] == 1)\n",
    "]\n",
    "plot_boxplots_all_features(fault_free_sample, \"Fault_Free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68325d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Distribution comparison\n",
    "plot_distribution_comparison(DF_F_TRAINING_RAW, DF_FF_TRAINING_RAW, fault_number=3, simulation_run=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. t-SNE visualization (warning: computationally intensive)\n",
    "print(\"Running t-SNE visualization... This may take a few minutes.\")\n",
    "plot_tsne_visualization(X_TRAIN, Y_TRAIN_DF, step=100)  # Increased step for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd45d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Scatter plot of first two features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_TRAIN[:, 0], X_TRAIN[:, 1], c=Y_TRAIN_DF, cmap=\"viridis\", alpha=0.5)\n",
    "plt.colorbar(label=\"Fault Number\")\n",
    "plt.title(\"Scatter Plot of First Two Features\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.grid()\n",
    "save_plot(\"scatter_first_two_features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08636784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Correlation analysis\n",
    "print(\"Generating correlation matrix with high correlations...\")\n",
    "plot_correlation_matrix(DF_FF_TRAINING_RAW, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdaf47d",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series_sample(df, fault_number=0, simulation_run=1, features_to_plot=5):\n",
    "    \"\"\"Plot time series for selected features.\"\"\"\n",
    "    df_sample = df[\n",
    "        (df[TARGET_VARIABLE_COLUMN_NAME] == fault_number) &\n",
    "        (df[SIMULATION_RUN_COLUMN_NAME] == simulation_run)\n",
    "    ]\n",
    "    \n",
    "    feature_columns = df_sample.columns[3:3+features_to_plot]  # First few features\n",
    "    \n",
    "    fig, axes = plt.subplots(len(feature_columns), 1, figsize=(15, 3 * len(feature_columns)))\n",
    "    \n",
    "    if len(feature_columns) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(feature_columns):\n",
    "        axes[i].plot(df_sample[\"sample\"] if \"sample\" in df_sample.columns else range(len(df_sample)), \n",
    "                    df_sample[col])\n",
    "        axes[i].set_xlabel(\"Sample\" if \"sample\" in df_sample.columns else \"Index\")\n",
    "        axes[i].set_ylabel(col)\n",
    "        axes[i].set_title(f\"{col.replace('_', ' ')} - Fault {fault_number}, Run {simulation_run}\")\n",
    "        axes[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_plot(\"time_series\", f\"fault_{fault_number}_run_{simulation_run}\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot time series for normal operation\n",
    "if \"sample\" in DF_FF_TRAINING_RAW.columns:\n",
    "    plot_time_series_sample(DF_FF_TRAINING_RAW, fault_number=0, simulation_run=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e52ae",
   "metadata": {},
   "source": [
    "## Summary Statistics Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save summary statistics\n",
    "if 'sample' not in DF_FF_TRAINING_RAW.columns:\n",
    "    feature_cols = DF_FF_TRAINING_RAW.columns[3:] if len(DF_FF_TRAINING_RAW.columns) > 3 else DF_FF_TRAINING_RAW.columns\n",
    "else:\n",
    "    feature_cols = [col for col in DF_FF_TRAINING_RAW.columns if col not in [TARGET_VARIABLE_COLUMN_NAME, SIMULATION_RUN_COLUMN_NAME, \"sample\", \"time\"]]\n",
    "\n",
    "summary_stats_normal = DF_FF_TRAINING_RAW[feature_cols].describe()\n",
    "save_dataframe(summary_stats_normal, \"summary_statistics_normal\", \"EDA\")\n",
    "\n",
    "summary_stats_faulty = DF_F_TRAINING_RAW[feature_cols].describe()\n",
    "save_dataframe(summary_stats_faulty, \"summary_statistics_faulty\", \"EDA\")\n",
    "\n",
    "# Class distribution\n",
    "class_distribution = DF_F_TRAINING_RAW[TARGET_VARIABLE_COLUMN_NAME].value_counts().sort_index()\n",
    "class_dist_df = pd.DataFrame({\n",
    "    'Fault_Number': class_distribution.index,\n",
    "    'Count': class_distribution.values\n",
    "})\n",
    "save_dataframe(class_dist_df, \"class_distribution\", \"EDA\")\n",
    "\n",
    "print(\"\\n=== EDA Summary ===\")\n",
    "print(f\"Normal data shape: {DF_FF_TRAINING_RAW.shape}\")\n",
    "print(f\"Faulty data shape: {DF_F_TRAINING_RAW.shape}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"\\nFault distribution:\")\n",
    "print(class_dist_df)\n",
    "\n",
    "print(\"\\n=== EDA Complete ===\")\n",
    "print(f\"All plots and statistics saved to: {OUTPUT_PATH}/{VERSION}/\")\n",
    "print(\"Files generated:\")\n",
    "print(\"- fault_statistics_EDA_*.csv\")\n",
    "print(\"- summary_statistics_*.csv\")\n",
    "print(\"- class_distribution_*.csv\")\n",
    "print(\"- Various plots in EDA/ subfolder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
