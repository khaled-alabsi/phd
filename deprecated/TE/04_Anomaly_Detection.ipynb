{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdf3c08",
   "metadata": {},
   "source": [
    "# Anomaly Detection Analysis\n",
    "\n",
    "This notebook implements and evaluates various anomaly detection methods for binary classification (normal vs fault) on the Tennessee Eastman Process dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "from typing import Union, Tuple\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Data preparation imports\n",
    "import pyreadr\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from scipy.stats import chi2\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ac565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VERSION = \"1.00\"\n",
    "OUTPUT_PATH = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69723f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(plot_name: str, suffix: str = \"\", plot_path: str = \"AnomalyDetection\") -> None:\n",
    "    \"\"\"Save current matplotlib figure.\"\"\"\n",
    "    timestamp: str = \"\"\n",
    "    base_dir: str = os.path.join(OUTPUT_PATH, \"data\", plot_path)\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename: str = f\"{plot_name}_{suffix}_v{VERSION}_{timestamp}.png\" if suffix else f\"{plot_name}_v{VERSION}_{timestamp}.png\"\n",
    "    filepath: str = os.path.join(base_dir, filename)\n",
    "\n",
    "    plt.savefig(filepath, bbox_inches=\"tight\", dpi=300)\n",
    "    print(f\"Plot saved: {filepath}\")\n",
    "\n",
    "def save_dataframe(df: pd.DataFrame, name: str, suffix: str = \"\") -> None:\n",
    "    \"\"\"Save a DataFrame to CSV.\"\"\"\n",
    "    timestamp: str = \"\"\n",
    "    base_dir: str = os.path.join(OUTPUT_PATH, \"data\")\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename: str = f\"{name}_{suffix}_v{VERSION}_{timestamp}.csv\" if suffix else f\"{name}_v{VERSION}_{timestamp}.csv\"\n",
    "    filepath: str = os.path.join(base_dir, filename)\n",
    "\n",
    "    df.to_csv(filepath, index=True)\n",
    "    print(f\"Data saved: {filepath}\")\n",
    "\n",
    "def save_pickle(obj, name: str, suffix: str = \"\") -> None:\n",
    "    \"\"\"Save object as pickle file.\"\"\"\n",
    "    timestamp: str = \"\"\n",
    "    base_dir: str = os.path.join(OUTPUT_PATH, \"data\")\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    filename: str = f\"{name}_{suffix}_v{VERSION}_{timestamp}.pkl\" if suffix else f\"{name}_v{VERSION}_{timestamp}.pkl\"\n",
    "    filepath: str = os.path.join(base_dir, filename)\n",
    "\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"Results saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef30bc8",
   "metadata": {},
   "source": [
    "## Load Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c352205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# STANDALONE ANOMALY DETECTION DATA PREPARATION\n",
    "# ====================================================================\n",
    "\n",
    "print(\"=== STANDALONE ANOMALY DETECTION DATA PREPARATION ===\")\n",
    "print(\"Preparing data specifically for binary anomaly detection (normal vs fault)...\")\n",
    "\n",
    "# Configuration for anomaly detection\n",
    "TARGET_VARIABLE_COLUMN_NAME = \"faultNumber\"\n",
    "SIMULATION_RUN_COLUMN_NAME = \"simulationRun\"\n",
    "COLUMNS_TO_REMOVE = [\"simulationRun\", \"sample\"]\n",
    "SKIPED_FAULTS = []\n",
    "\n",
    "# Load raw data\n",
    "print(\"Loading raw data files...\")\n",
    "fault_free_training_dict = pyreadr.read_r(\"data/TEP_FaultFree_Training.RData\")\n",
    "fault_free_testing_dict = pyreadr.read_r(\"data/TEP_FaultFree_Testing.RData\")\n",
    "faulty_training_dict = pyreadr.read_r(\"data/TEP_Faulty_Training.RData\")\n",
    "faulty_testing_dict = pyreadr.read_r(\"data/TEP_Faulty_Testing.RData\")\n",
    "\n",
    "# Extract DataFrames\n",
    "DF_FF_TRAINING_RAW = fault_free_training_dict[\"fault_free_training\"]\n",
    "DF_FF_TEST_RAW = fault_free_testing_dict[\"fault_free_testing\"]\n",
    "DF_F_TRAINING_RAW = faulty_training_dict[\"faulty_training\"]\n",
    "DF_F_TEST_RAW = faulty_testing_dict[\"faulty_testing\"]\n",
    "\n",
    "print(f\"✓ Raw data loaded: Train Fault-free {DF_FF_TRAINING_RAW.shape}, Train Faulty {DF_F_TRAINING_RAW.shape}\")\n",
    "\n",
    "# Skip specified faults (if any)\n",
    "DF_F_TRAIN_SKIPPED = DF_F_TRAINING_RAW[~DF_F_TRAINING_RAW[TARGET_VARIABLE_COLUMN_NAME].isin(SKIPED_FAULTS)].reset_index(drop=True)\n",
    "DF_F_TEST_SKIPPED = DF_F_TEST_RAW[~DF_F_TEST_RAW[TARGET_VARIABLE_COLUMN_NAME].isin(SKIPED_FAULTS)].reset_index(drop=True)\n",
    "\n",
    "# Reduce data for development\n",
    "DF_FF_TRAINING_REDUCED = DF_FF_TRAINING_RAW[(DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] > 0) & \n",
    "                                           (DF_FF_TRAINING_RAW[SIMULATION_RUN_COLUMN_NAME] < 3)].drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "DF_F_TRAINING_REDUCED = DF_F_TRAIN_SKIPPED[(DF_F_TRAIN_SKIPPED[SIMULATION_RUN_COLUMN_NAME] > 0) & \n",
    "                                          (DF_F_TRAIN_SKIPPED[SIMULATION_RUN_COLUMN_NAME] < 3)].drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "DF_FF_TEST_REDUCED = DF_FF_TEST_RAW[(DF_FF_TEST_RAW[SIMULATION_RUN_COLUMN_NAME] > 0) & \n",
    "                                   (DF_FF_TEST_RAW[SIMULATION_RUN_COLUMN_NAME] < 3)].drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "DF_F_TEST_REDUCED = DF_F_TEST_SKIPPED[(DF_F_TEST_SKIPPED[SIMULATION_RUN_COLUMN_NAME] > 0) & \n",
    "                                     (DF_F_TEST_SKIPPED[SIMULATION_RUN_COLUMN_NAME] < 3)].drop(columns=COLUMNS_TO_REMOVE, axis=1)\n",
    "\n",
    "print(f\"✓ Data reduced for anomaly detection\")\n",
    "\n",
    "# Prepare anomaly detection datasets\n",
    "# In-control (normal) data - only fault-free\n",
    "X_INCONTROL_TRAIN_REDUCED = DF_FF_TRAINING_REDUCED.drop(columns=[TARGET_VARIABLE_COLUMN_NAME], axis=1).to_numpy()\n",
    "X_INCONTROL_TEST_REDUCED = DF_FF_TEST_REDUCED.drop(columns=[TARGET_VARIABLE_COLUMN_NAME], axis=1).to_numpy()\n",
    "\n",
    "# Out-of-control (faulty) data\n",
    "X_OUT_OF_CONTROL_TEST_REDUCED = DF_F_TEST_REDUCED.drop(columns=[TARGET_VARIABLE_COLUMN_NAME], axis=1).to_numpy()\n",
    "\n",
    "# Create binary labels for anomaly detection (0 = normal, 1 = anomaly)\n",
    "# Training labels - all normal (in-control) for unsupervised methods\n",
    "Y_TRAIN_ANOMALY_REDUCED_DF = pd.Series([0] * len(X_INCONTROL_TRAIN_REDUCED))\n",
    "\n",
    "# Test labels - normal + faulty\n",
    "normal_test_labels = [0] * len(X_INCONTROL_TEST_REDUCED)\n",
    "fault_test_labels = [1] * len(X_OUT_OF_CONTROL_TEST_REDUCED)\n",
    "Y_TEST_ANOMALY_REDUCED_DF = pd.Series(normal_test_labels + fault_test_labels)\n",
    "\n",
    "# Combine test features (normal + faulty)\n",
    "X_TEST_REDUCED = np.concatenate([X_INCONTROL_TEST_REDUCED, X_OUT_OF_CONTROL_TEST_REDUCED], axis=0)\n",
    "\n",
    "# For supervised methods - prepare combined training data (normal + faulty training)\n",
    "DF_TRAINING_REDUCED_CONCATED = pd.concat([DF_FF_TRAINING_REDUCED, DF_F_TRAINING_REDUCED], ignore_index=True)\n",
    "X_TRAIN_SUPERVISED = DF_TRAINING_REDUCED_CONCATED.drop(columns=[TARGET_VARIABLE_COLUMN_NAME], axis=1).to_numpy()\n",
    "\n",
    "# Create labels for supervised training: 0 for normal, 1 for any fault\n",
    "Y_TRAIN_SUPERVISED = pd.Series([0] * len(DF_FF_TRAINING_REDUCED) + [1] * len(DF_F_TRAINING_REDUCED))\n",
    "\n",
    "# Standardize features for anomaly detection\n",
    "sc_anomaly = StandardScaler()\n",
    "X_INCONTROL_TRAIN_REDUCED = sc_anomaly.fit_transform(X_INCONTROL_TRAIN_REDUCED)\n",
    "X_INCONTROL_TEST_REDUCED = sc_anomaly.transform(X_INCONTROL_TEST_REDUCED)\n",
    "X_OUT_OF_CONTROL_TEST_REDUCED = sc_anomaly.transform(X_OUT_OF_CONTROL_TEST_REDUCED)\n",
    "X_TEST_REDUCED = sc_anomaly.transform(X_TEST_REDUCED)\n",
    "\n",
    "# Scale supervised training data using the same scaler\n",
    "X_TRAIN_SUPERVISED = sc_anomaly.transform(X_TRAIN_SUPERVISED)\n",
    "\n",
    "# For neural networks - one-hot encode binary labels\n",
    "# Need to specify categories explicitly since training only has class 0\n",
    "encoder_anomaly = OneHotEncoder(sparse_output=False, categories=[[0, 1]])\n",
    "Y_reshaped_anomaly = Y_TRAIN_SUPERVISED.to_numpy().reshape(-1, 1)\n",
    "Y_ENC_ANOMALY_TRAIN_REDUCED = encoder_anomaly.fit_transform(Y_reshaped_anomaly)\n",
    "\n",
    "Y_test_reshaped_anomaly = Y_TEST_ANOMALY_REDUCED_DF.to_numpy().reshape(-1, 1)\n",
    "Y_ENC_ANOMALY_TEST_REDUCED = encoder_anomaly.transform(Y_test_reshaped_anomaly)\n",
    "\n",
    "print(f\"✓ Anomaly detection data prepared:\")\n",
    "print(f\"✓ In-control training data: {X_INCONTROL_TRAIN_REDUCED.shape}\")\n",
    "print(f\"✓ In-control test data: {X_INCONTROL_TEST_REDUCED.shape}\")\n",
    "print(f\"✓ Out-of-control test data: {X_OUT_OF_CONTROL_TEST_REDUCED.shape}\")\n",
    "print(f\"✓ Combined test data: {X_TEST_REDUCED.shape}\")\n",
    "print(f\"✓ Supervised training data: {X_TRAIN_SUPERVISED.shape}\")\n",
    "print(f\"✓ Supervised training labels: {Y_TRAIN_SUPERVISED.value_counts().to_dict()}\")\n",
    "print(f\"✓ Test labels distribution: {Y_TEST_ANOMALY_REDUCED_DF.value_counts().to_dict()}\")\n",
    "print(\"=== ANOMALY DETECTION DATA PREPARATION COMPLETE ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658892e4",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_detection_metrics(predicted, true_labels: NDArray[np.int64]) -> pd.DataFrame:\n",
    "    \"\"\"Compute comprehensive detection metrics for binary classification.\"\"\"\n",
    "    y_pred = predicted.astype(int)\n",
    "    y_true = true_labels.astype(int)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    acc: float = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec: float = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec: float = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    tnr: float = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    fpr: float = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    npv: float = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "    bal_acc: float = 0.5 * (rec + tnr)\n",
    "    f1: float = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "    \n",
    "    return pd.DataFrame([{\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall / TPR\": rec,\n",
    "        \"F1-Score\": f1,\n",
    "        \"FPR\": fpr,\n",
    "        \"NPV (Negative Predictive Value)\": npv,\n",
    "        \"Balanced Accuracy\": bal_acc,\n",
    "    }])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc741b",
   "metadata": {},
   "source": [
    "## MCUSUM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_incontrol_parameters(\n",
    "    X_incontrol: NDArray[np.float64],\n",
    ") -> tuple[NDArray[np.float64], NDArray[np.float64]]:\n",
    "    \"\"\"Estimate in-control mean and covariance.\"\"\"\n",
    "    mu_0 = np.mean(X_incontrol, axis=0)\n",
    "    sigma = np.cov(X_incontrol, rowvar=False, bias=False)\n",
    "    return mu_0, sigma\n",
    "\n",
    "def compute_mcusum_scores(\n",
    "    X_test: NDArray[np.float64],\n",
    "    mu_0: NDArray[np.float64],\n",
    "    sigma: NDArray[np.float64],\n",
    "    k: float,\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"Compute MCUSUM statistics.\"\"\"\n",
    "    X_test = np.asarray(X_test)\n",
    "    mu_0 = np.asarray(mu_0)\n",
    "    sigma = np.asarray(sigma)\n",
    "\n",
    "    n_samples, n_features = X_test.shape\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eigh(sigma)\n",
    "    eigvals_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals))\n",
    "    sigma_inv_sqrt = eigvecs @ eigvals_inv_sqrt @ eigvecs.T\n",
    "\n",
    "    Z = (X_test - mu_0) @ sigma_inv_sqrt.T\n",
    "\n",
    "    S_t = np.zeros(n_features)\n",
    "    T = np.zeros(n_samples)\n",
    "\n",
    "    for t in range(n_samples):\n",
    "        V_t = S_t + Z[t]\n",
    "        norm_V_t = np.linalg.norm(V_t)\n",
    "\n",
    "        if norm_V_t <= k:\n",
    "            S_t = np.zeros(n_features)\n",
    "        else:\n",
    "            shrinkage = 1.0 - k / norm_V_t\n",
    "            S_t = V_t * shrinkage\n",
    "\n",
    "        T[t] = np.linalg.norm(S_t)\n",
    "\n",
    "    return T\n",
    "\n",
    "def estimate_h(\n",
    "    x_incontrol_np: NDArray[np.float64],\n",
    "    k: float = 0.5,\n",
    "    percentile_threshold: int = 98,\n",
    ") -> float:\n",
    "    \"\"\"Estimate control limit h.\"\"\"\n",
    "    mu_0, sigma = estimate_incontrol_parameters(x_incontrol_np)\n",
    "\n",
    "    n_simulations = 500\n",
    "    max_T_values = []\n",
    "\n",
    "    for i in range(n_simulations):\n",
    "        indices = np.random.choice(x_incontrol_np.shape[0], size=300, replace=True)\n",
    "        sample = x_incontrol_np[indices]\n",
    "        T = compute_mcusum_scores(sample, mu_0, sigma, k=k)\n",
    "        max_T_values.append(np.max(T))\n",
    "\n",
    "    h = np.percentile(max_T_values, percentile_threshold)\n",
    "    print(f\"Estimated control limit h: {h}\")\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad8e52",
   "metadata": {},
   "source": [
    "## PCA-based Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaafd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca_model(\n",
    "        X_train: NDArray[np.float64],\n",
    "        n_components=0.9,\n",
    "        contamination: float = 0.05) -> Tuple[StandardScaler, PCA, float]:\n",
    "    \"\"\"Train PCA model and compute anomaly threshold.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "    errors = np.sum((X_scaled - X_reconstructed)**2, axis=1)\n",
    "    threshold_index = int((1 - contamination) * len(errors))\n",
    "    threshold = np.sort(errors)[threshold_index]\n",
    "\n",
    "    print(f\"PCA components retained: {pca.n_components_}\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "    print(f\"Reconstruction error threshold: {threshold:.3f}\")\n",
    "\n",
    "    return scaler, pca, threshold\n",
    "\n",
    "def detect_anomalies_pca(\n",
    "    X_test: NDArray[np.float64],\n",
    "    scaler: StandardScaler,\n",
    "    pca: PCA,\n",
    "    threshold: float,\n",
    ") -> Tuple[NDArray[np.float64], NDArray[np.int64]]:\n",
    "    \"\"\"Apply PCA-based anomaly detection.\"\"\"\n",
    "    X_scaled = scaler.transform(X_test)\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "    X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "    reconstruction_errors = np.sum((X_scaled - X_reconstructed)**2, axis=1)\n",
    "    anomaly_flags = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "    return reconstruction_errors, anomaly_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132d687",
   "metadata": {},
   "source": [
    "## Autoencoder Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81813be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_autoencoder(input_dim: int, latent_dim: int = None) -> keras.Model:\n",
    "    \"\"\"Build autoencoder model.\"\"\"\n",
    "    if latent_dim is None:\n",
    "        latent_dim = max(4, min(64, input_dim // 20))\n",
    "\n",
    "    # Encoder\n",
    "    input_layer = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(max(32, input_dim // 2), activation='relu')(input_layer)\n",
    "    x = layers.Dense(max(16, input_dim // 4), activation='relu')(x)\n",
    "    encoded = layers.Dense(latent_dim, activation='relu')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Dense(max(16, input_dim // 4), activation='relu')(encoded)\n",
    "    x = layers.Dense(max(32, input_dim // 2), activation='relu')(x)\n",
    "    output_layer = layers.Dense(input_dim, activation='linear')(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_autoencoder(X_train: np.ndarray, model: keras.Model, n_epochs: int = 100) -> keras.Model:\n",
    "    \"\"\"Train autoencoder.\"\"\"\n",
    "    if X_train.dtype != np.float32:\n",
    "        X_train = X_train.astype(np.float32)\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\",\n",
    "        patience=10,\n",
    "        min_delta=1e-6,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=n_epochs,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def compute_reconstruction_error(model: keras.Model, X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute reconstruction error.\"\"\"\n",
    "    if X.dtype != np.float32:\n",
    "        X = X.astype(np.float32)\n",
    "\n",
    "    X_reconstructed = model.predict(X, verbose=0)\n",
    "    squared_error = np.sum((X - X_reconstructed)**2, axis=1)\n",
    "\n",
    "    return squared_error\n",
    "\n",
    "def detect_anomalies_from_error(errors: np.ndarray, contamination: float = 0.05) -> np.ndarray:\n",
    "    \"\"\"Flag anomalies based on reconstruction error.\"\"\"\n",
    "    threshold_idx = int((1 - contamination) * len(errors))\n",
    "    threshold = np.sort(errors)[threshold_idx]\n",
    "    return (errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90b1e6",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results storage\n",
    "anomaly_results_per_model: dict[str, pd.DataFrame] = {}\n",
    "trained_models_anomaly: dict[str, object] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267613b",
   "metadata": {},
   "source": [
    "### 1. MCUSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training MCUSUM...\")\n",
    "\n",
    "# Estimate parameters\n",
    "mu_0, sigma = estimate_incontrol_parameters(X_INCONTROL_TRAIN_REDUCED)\n",
    "delta = np.ones(X_INCONTROL_TRAIN_REDUCED.shape[1]) * 0.1\n",
    "k = 0.5  # Reference value\n",
    "h = estimate_h(X_INCONTROL_TRAIN_REDUCED, k, 99)\n",
    "\n",
    "# Compute statistics\n",
    "mcusum_statistics = compute_mcusum_scores(X_TEST_REDUCED, mu_0, sigma, k)\n",
    "mcusum_flags = mcusum_statistics > h\n",
    "\n",
    "# Evaluate\n",
    "mcusum_metrics = compute_detection_metrics(mcusum_flags.astype(int), Y_TEST_ANOMALY_REDUCED_DF)\n",
    "anomaly_results_per_model[\"MCUSUM\"] = mcusum_metrics\n",
    "trained_models_anomaly[\"MCUSUM\"] = {'mu_0': mu_0, 'sigma': sigma, 'k': k, 'h': h}\n",
    "\n",
    "print(f\"MCUSUM - Control limit: {h:.3f}\")\n",
    "print(f\"MCUSUM - Out-of-control points: {np.sum(mcusum_flags)} / {len(mcusum_flags)}\")\n",
    "print(f\"MCUSUM - Accuracy: {mcusum_metrics['Accuracy'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c3e26",
   "metadata": {},
   "source": [
    "### 2. PCA-based Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training PCA...\")\n",
    "\n",
    "# Train PCA model using supervised training data\n",
    "scaler_pca, pca_model, threshold_pca = train_pca_model(\n",
    "    X_TRAIN_SUPERVISED, n_components=0.9, contamination=0.05\n",
    ")\n",
    "\n",
    "# Detect anomalies\n",
    "errors_pca, y_pred_pca = detect_anomalies_pca(\n",
    "    X_TEST_REDUCED, scaler_pca, pca_model, threshold_pca\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "pca_metrics = compute_detection_metrics(y_pred_pca, Y_TEST_ANOMALY_REDUCED_DF)\n",
    "anomaly_results_per_model[\"PCA\"] = pca_metrics\n",
    "trained_models_anomaly[\"PCA\"] = {\n",
    "    'scaler': scaler_pca, 'pca': pca_model, 'threshold': threshold_pca\n",
    "}\n",
    "\n",
    "print(f\"PCA - Accuracy: {pca_metrics['Accuracy'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd6bef",
   "metadata": {},
   "source": [
    "### 3. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Autoencoder...\")\n",
    "\n",
    "# Build and train autoencoder using supervised training data\n",
    "input_dim = X_TRAIN_SUPERVISED.shape[1]\n",
    "autoencoder_model = build_autoencoder(input_dim)\n",
    "autoencoder_model = train_autoencoder(X_TRAIN_SUPERVISED, autoencoder_model)\n",
    "\n",
    "# Detect anomalies\n",
    "errors_ae = compute_reconstruction_error(autoencoder_model, X_TEST_REDUCED)\n",
    "y_pred_ae = detect_anomalies_from_error(errors_ae, contamination=0.05)\n",
    "\n",
    "# Evaluate\n",
    "ae_metrics = compute_detection_metrics(y_pred_ae, Y_TEST_ANOMALY_REDUCED_DF)\n",
    "anomaly_results_per_model[\"Autoencoder\"] = ae_metrics\n",
    "trained_models_anomaly[\"Autoencoder\"] = autoencoder_model\n",
    "\n",
    "print(f\"Autoencoder - Accuracy: {ae_metrics['Accuracy'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a61bb",
   "metadata": {},
   "source": [
    "### 4. Random Forest (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d334ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest for anomaly detection...\")\n",
    "\n",
    "# Train model using supervised training data\n",
    "rf_anomaly = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_anomaly.fit(X_TRAIN_SUPERVISED, Y_TRAIN_SUPERVISED)\n",
    "y_pred_rf_anomaly = rf_anomaly.predict(X_TEST_REDUCED)\n",
    "\n",
    "# Evaluate\n",
    "rf_anomaly_metrics = compute_detection_metrics(y_pred_rf_anomaly, Y_TEST_ANOMALY_REDUCED_DF)\n",
    "anomaly_results_per_model[\"Random Forest\"] = rf_anomaly_metrics\n",
    "trained_models_anomaly[\"Random Forest\"] = rf_anomaly\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {rf_anomaly_metrics['Accuracy'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd18838",
   "metadata": {},
   "source": [
    "### 5. XGBoost (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58141de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training XGBoost for anomaly detection...\")\n",
    "\n",
    "# Train model using supervised training data\n",
    "xg_anomaly = xgb.XGBClassifier(random_state=42)\n",
    "xg_anomaly.fit(X_TRAIN_SUPERVISED, Y_TRAIN_SUPERVISED)\n",
    "y_pred_xg_anomaly = xg_anomaly.predict(X_TEST_REDUCED)\n",
    "\n",
    "# Evaluate\n",
    "xg_anomaly_metrics = compute_detection_metrics(y_pred_xg_anomaly, Y_TEST_ANOMALY_REDUCED_DF)\n",
    "anomaly_results_per_model[\"XGBoost\"] = xg_anomaly_metrics\n",
    "trained_models_anomaly[\"XGBoost\"] = xg_anomaly\n",
    "\n",
    "print(f\"XGBoost - Accuracy: {xg_anomaly_metrics['Accuracy'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15c9212",
   "metadata": {},
   "source": [
    "### 6. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training LightGBM...\")\n",
    "\n",
    "# Train model using supervised training data\n",
    "train_set = lgb.Dataset(X_TRAIN_SUPERVISED, label=Y_TRAIN_SUPERVISED)\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 31,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "model_lgb = lgb.train(params, train_set, num_boost_round=100)\n",
    "\n",
    "# Predict\n",
    "y_proba_lgb = model_lgb.predict(X_TEST_REDUCED)\n",
    "y_pred_lgb = (y_proba_lgb >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "lgb_metrics = compute_detection_metrics(y_pred_lgb, Y_TEST_ANOMALY_REDUCED_DF)\n",
    "anomaly_results_per_model[\"LightGBM\"] = lgb_metrics\n",
    "trained_models_anomaly[\"LightGBM\"] = model_lgb\n",
    "\n",
    "print(f\"LightGBM - Accuracy: {lgb_metrics['Accuracy'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89504f7",
   "metadata": {},
   "source": [
    "### 7. Neural Network (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522dd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Neural Network for anomaly detection...\")\n",
    "\n",
    "# Import additional required modules\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Define model\n",
    "inputs = Input(shape=(X_TRAIN_SUPERVISED.shape[1],))\n",
    "x = Dense(100, activation=\"selu\")(inputs)\n",
    "x = Dense(100, activation=\"selu\")(x)\n",
    "x = Dense(100, activation=\"selu\")(x)\n",
    "x = Dense(100, activation=\"selu\")(x)\n",
    "outputs = Dense(Y_ENC_ANOMALY_TEST_REDUCED.shape[1], activation=\"softmax\")(x)\n",
    "\n",
    "model_anomaly_nn = Model(inputs=inputs, outputs=outputs)\n",
    "model_anomaly_nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "history_anomaly = model_anomaly_nn.fit(\n",
    "    X_TRAIN_SUPERVISED,\n",
    "    Y_ENC_ANOMALY_TRAIN_REDUCED,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_TEST_REDUCED, Y_ENC_ANOMALY_TEST_REDUCED),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_proba_nn = model_anomaly_nn.predict(X_TEST_REDUCED, verbose=0)\n",
    "y_pred_anomaly_nn = encoder_anomaly.inverse_transform(y_pred_proba_nn).flatten()\n",
    "\n",
    "# Evaluate\n",
    "nn_anomaly_metrics = compute_detection_metrics(y_pred_anomaly_nn, Y_TEST_ANOMALY_REDUCED_DF)\n",
    "anomaly_results_per_model[\"Neural Network\"] = nn_anomaly_metrics\n",
    "trained_models_anomaly[\"Neural Network\"] = model_anomaly_nn\n",
    "\n",
    "print(f\"Neural Network - Accuracy: {nn_anomaly_metrics['Accuracy'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb79c67",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d50fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results\n",
    "def convert_result_dict_to_df(results_dict):\n",
    "    \"\"\"Convert results dictionary to DataFrame.\"\"\"\n",
    "    results_df = pd.concat(\n",
    "        [df.assign(Model=model) for model, df in results_dict.items()],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    cols = ['Model'] + [col for col in results_df.columns if col != 'Model']\n",
    "    results_df = results_df[cols]\n",
    "    return results_df\n",
    "\n",
    "concatenated_anomaly_results_df = convert_result_dict_to_df(anomaly_results_per_model)\n",
    "save_dataframe(concatenated_anomaly_results_df, \"anomaly_detection_metrics\", \"anomaly\")\n",
    "\n",
    "print(\"\\n=== Anomaly Detection Results ===\")\n",
    "print(tabulate(concatenated_anomaly_results_df, headers=\"keys\", tablefmt=\"grid\", floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomaly_detection_comparison(metrics_dict) -> None:\n",
    "    \"\"\"Plot anomaly detection model comparison.\"\"\"\n",
    "    df_combined = pd.concat(\n",
    "        [df.assign(Model=model) for model, df in metrics_dict.items()],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    df_melted = df_combined.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    model_list = df_melted[\"Model\"].unique().tolist()\n",
    "    metric_list = df_melted[\"Metric\"].unique().tolist()\n",
    "    n_models = len(model_list)\n",
    "    bar_width = 0.12\n",
    "    group_spacing = 0.8\n",
    "\n",
    "    base_positions = [\n",
    "        i * (n_models * bar_width + group_spacing)\n",
    "        for i in range(len(metric_list))\n",
    "    ]\n",
    "\n",
    "    for model_idx, model in enumerate(model_list):\n",
    "        subset = df_melted[df_melted[\"Model\"] == model]\n",
    "        bar_positions = [pos + bar_width * model_idx for pos in base_positions]\n",
    "        plt.bar(bar_positions, subset[\"Value\"], width=bar_width, label=model)\n",
    "\n",
    "    tick_positions = [\n",
    "        pos + (bar_width * n_models / 2) - (bar_width / 2)\n",
    "        for pos in base_positions\n",
    "    ]\n",
    "    plt.xticks(tick_positions, metric_list, rotation=45, ha=\"right\")\n",
    "\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Anomaly Detection Model Comparison\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.tight_layout()\n",
    "    save_plot(\"anomaly_detection_comparison\")\n",
    "    plt.show()\n",
    "\n",
    "plot_anomaly_detection_comparison(anomaly_results_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for top performing models\n",
    "def plot_confusion_matrix_binary(y_true, y_pred, title: str):\n",
    "    \"\"\"Plot confusion matrix for binary classification.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\".2f\", \n",
    "                xticklabels=[\"Normal\", \"Anomaly\"], \n",
    "                yticklabels=[\"Normal\", \"Anomaly\"])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    safe_title = title.replace(\" \", \"_\").lower()\n",
    "    save_plot(f\"confusion_matrix_{safe_title}\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices for best performing models\n",
    "plot_confusion_matrix_binary(Y_TEST_ANOMALY_REDUCED_DF, y_pred_rf_anomaly, \"Random Forest\")\n",
    "plot_confusion_matrix_binary(Y_TEST_ANOMALY_REDUCED_DF, y_pred_xg_anomaly, \"XGBoost\")\n",
    "plot_confusion_matrix_binary(Y_TEST_ANOMALY_REDUCED_DF, y_pred_ae, \"Autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9333d",
   "metadata": {},
   "source": [
    "## Export Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ddb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "for model_name, model_obj in trained_models_anomaly.items():\n",
    "    safe_name = model_name.lower().replace(\" \", \"_\")\n",
    "    save_pickle(model_obj, f\"anomaly_model_{safe_name}\")\n",
    "\n",
    "# Create comprehensive results summary\n",
    "best_model_idx = concatenated_anomaly_results_df['Accuracy'].idxmax()\n",
    "best_model = concatenated_anomaly_results_df.loc[best_model_idx, 'Model']\n",
    "best_accuracy = concatenated_anomaly_results_df['Accuracy'].max()\n",
    "best_f1 = concatenated_anomaly_results_df['F1-Score'].max()\n",
    "\n",
    "results_summary = {\n",
    "    'best_model': best_model,\n",
    "    'best_accuracy': best_accuracy,\n",
    "    'best_f1': best_f1,\n",
    "    'models_trained': list(anomaly_results_per_model.keys()),\n",
    "    'total_test_samples': len(Y_TEST_ANOMALY_REDUCED_DF),\n",
    "    'normal_samples': int((Y_TEST_ANOMALY_REDUCED_DF == 0).sum()),\n",
    "    'anomaly_samples': int((Y_TEST_ANOMALY_REDUCED_DF == 1).sum())\n",
    "}\n",
    "\n",
    "# Save results summary\n",
    "import json\n",
    "summary_path = os.path.join(OUTPUT_PATH, VERSION, f\"anomaly_detection_summary_v{VERSION}_.json\")\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"\\n=== Anomaly Detection Analysis Complete ===\")\n",
    "print(f\"Best performing model: {best_model}\")\n",
    "print(f\"Best accuracy: {best_accuracy:.3f}\")\n",
    "print(f\"Best F1-score: {best_f1:.3f}\")\n",
    "print(f\"Normal samples: {results_summary['normal_samples']}\")\n",
    "print(f\"Anomaly samples: {results_summary['anomaly_samples']}\")\n",
    "print(f\"\\nResults saved to: {OUTPUT_PATH}/{VERSION}/\")\n",
    "print(\"Files generated:\")\n",
    "print(\"- anomaly_detection_metrics_anomaly_*.csv\")\n",
    "print(\"- anomaly_detection_summary_*.json\")\n",
    "print(\"- anomaly_model_*.pkl (trained models)\")\n",
    "print(\"- Various plots in anomaly/ subfolder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
