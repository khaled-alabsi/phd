# **Benchmarking Methodologies in Multivariate Statistical Process Control**

**1\. Introduction to Benchmarking in Multivariate Statistical Process Control**

Benchmarking plays a crucial role in the evolution and validation of Multivariate Statistical Process Control (MSPC) techniques. As the complexity of industrial processes increases, the need for effective monitoring and fault detection methods has become paramount.1 Evaluating the performance of newly developed MSPC methodologies requires a systematic approach to determine their efficacy in comparison to existing ones. However, a significant challenge in the field has been the absence of standardized data and universally accepted procedures for this comparative assessment.3 This lack of standardization can lead to difficulties in objectively ascertaining whether a novel method genuinely outperforms established techniques, as evaluations might be conducted under varying conditions and using different metrics. Therefore, identifying and utilizing resources that enable objective and reproducible evaluations is essential for the advancement of MSPC.

The absence of readily available standardized benchmarks can impede the objective assessment of new MSPC methods. Without a common ground for comparison, researchers might employ disparate datasets and evaluation criteria, making it challenging to ascertain the true merit of a proposed technique.3 This situation can potentially lead to subjective evaluations and a slower rate of progress in the field, as the adoption of truly superior methods might be hindered by a lack of clear, comparative evidence. Conversely, the development and widespread adoption of standardized benchmarks can significantly benefit the MSPC research community. By providing a common framework for evaluating and comparing different approaches, standardized datasets and methodologies can foster collaboration, facilitate knowledge sharing, and ultimately lead to the identification of best practices in MSPC.3 When researchers utilize the same datasets and benchmarking methods, their results become directly comparable, allowing for a more objective assessment of the strengths and weaknesses of various techniques.

**2\. Standardized Datasets for Benchmarking MSPC Methods**

For effective benchmarking of MSPC techniques, it is imperative to utilize datasets that possess well-defined characteristics, including the presence of known fault conditions or process variations. These datasets serve as a common ground for evaluating the ability of different MSPC methods to accurately detect and diagnose process anomalies.

**2.1. The Tennessee Eastman Process (TEP) Dataset**

The Tennessee Eastman Process (TEP) dataset stands out as a widely recognized benchmark in the realm of process control and fault diagnosis research.4 It simulates a complex industrial chemical process originally modeled by Downs and Vogel, encompassing a reactor, condenser, gas-liquid separator, centrifugal compressor, and stripper.5 This dataset has been extensively employed in both academia and industry for the purpose of testing and comparing various machine learning algorithms, particularly those related to fault detection, diagnosis, and process monitoring.4 The TEP dataset is structured to include both fault-free and faulty datasets, with the latter containing simulations of various process faults. The most widely used version comprises 22 datasets, 21 of which contain specific faults (numbered 1 through 21), while one dataset (Fault 0$ represents normal, fault-free operation.6 These datasets typically include 52 process variables, which are sampled at a rate of 3 minutes.6 The simulated faults cover a range of issues that can occur in a chemical plant, providing a diverse set of conditions for benchmarking.5 The dataset is readily accessible through various online repositories, including Harvard Dataverse 5, and GitHub 6, often with accompanying documentation and tools for data loading and preprocessing.6

The TEP dataset's widespread popularity as a benchmark stems from its realistic simulation of an industrial process and the inclusion of a diverse array of fault scenarios.5 The complexity inherent in the interconnected variables and the variety of fault types allow researchers to rigorously test the capabilities of MSPC methods in addressing challenges that are representative of real-world industrial environments. Furthermore, the availability of both normal and faulty data is crucial, as it enables the evaluation of both the false alarm rates (on the fault-free data) and the fault detection rates (on the faulty data) of the MSPC techniques being benchmarked. Beyond the original TEP dataset, several versions and extensions have been developed to cater to different benchmarking needs. For instance, extensions incorporating different operating modes 11 or longer simulation periods 9 have been created. These variations provide opportunities for more comprehensive benchmarking under a broader range of conditions, such as assessing the robustness of MSPC methods to non-stationarity arising from operating mode changes or their long-term reliability.

**2.2. SECOM and ST-AWFD Datasets**

The SECOM and ST-AWFD datasets are mentioned in the context of benchmarking a privacy-preserving federated MSPC framework.12 While the provided snippets do not offer extensive details regarding their accessibility or specific characteristics, their utilization in a comparative study suggests their potential value for standardized MSPC benchmarking. A study testing a federated PCA approach employed these datasets to demonstrate its superior fault detection capability when compared to standard, single-party (multiway) PCA.12 This implies that both SECOM and ST-AWFD are likely industrial benchmark datasets containing multivariate process data with known fault conditions, making them relevant for evaluating the performance of MSPC methods. Further research into the origins and structures of these datasets would be beneficial to fully understand their suitability for broader benchmarking purposes.

**2.3. Other Potential Datasets**

Several other datasets are mentioned across the research snippets that might hold potential for MSPC benchmarking, depending on the specific application and requirements. These include datasets related to bearing faults, such as the IMS Bearing Dataset and the Paderbone University Bearing Fault Benchmark.13 These datasets typically contain vibration data collected from bearing experiments under various fault conditions, which could be useful for benchmarking MSPC methods specifically designed for monitoring rotating machinery in production lines.14 The EUPPBench dataset, focused on weather forecasting 3, while multivariate, might be less directly applicable to benchmarking general MSPC techniques in typical industrial production scenarios due to the different nature of the processes and variables involved. Similarly, datasets like those from Intel Lab, SensorScope, and Smart Santander 15, which contain sensor data with injected faults, could be valuable for benchmarking MSPC methods aimed at sensor fault detection and validation within industrial processes. The PRONTO heterogeneous benchmark dataset, based on an industrial-scale multiphase flow facility, includes diverse data sources and induced faults, making it a potentially relevant resource for benchmarking MSPC methods in complex industrial settings.13 The suitability of each dataset for MSPC benchmarking hinges on its alignment with the characteristics of typical industrial production processes, particularly the multivariate nature of the data and the presence of known faults or anomalies that are relevant to process control.

**Table 1: Summary of Standardized Datasets for MSPC Benchmarking**

| Dataset Name | Description | Key Features | Access Link |
| :---- | :---- | :---- | :---- |
| Tennessee Eastman Process (TEP) | Simulation of a complex industrial chemical process | 52 variables, 22 datasets (21 faulty, 1 fault-free), 3-minute sampling rate | Various repositories (Harvard Dataverse, GitHub) |
| SECOM | Industrial benchmark dataset for fault detection | Multivariate process data, known fault conditions | Requires further investigation to determine public availability |
| ST-AWFD | Industrial benchmark dataset for fault detection | Multivariate process data, known fault conditions | Requires further investigation to determine public availability |
| IMS Bearing Dataset | Bearing acceleration data from run-to-failure experiments | Multivariate time-series data, various bearing fault conditions | Requires further investigation to determine public availability |
| Paderbone University Bearing Fault | Motor current signal data for condition monitoring of rolling bearings | Multivariate time-series data, various bearing fault conditions | Requires further investigation to determine public availability |
| PRONTO | Heterogeneous dataset from an industrial-scale multiphase flow facility | Process measurements, alarms, ultrasonic data, operation logs, video | Requires further investigation to determine public availability |
| Intel Lab Sensor Data | Temperature and light data from indoor sensors with injected faults | Multivariate time-series data, various fault types (random, malfunction, etc.) | Requires further investigation to determine public availability |
| SensorScope Sensor Data | Outdoor temperature data from sensors with injected faults | Multivariate time-series data, various fault types (random, malfunction, etc.) | Requires further investigation to determine public availability |
| Smart Santander Sensor Data | Outdoor temperature data from sensors with injected faults | Multivariate time-series data, various fault types (random, malfunction, etc.) | Requires further investigation to determine public availability |

**3\. Methodologies for Benchmarking MSPC Techniques: Detailed Explanations and Numerical Examples**

Various MSPC methods are employed for benchmarking, each with its own underlying principles and suitability for different types of process data and fault characteristics. These methods can broadly be categorized into multivariate control charts and projection methods.

**3.1. Multivariate Control Charts**

Multivariate control charts extend the principles of traditional univariate control charts to simultaneously monitor multiple quality characteristics of a process. These charts are essential tools for detecting when a process deviates from its normal operating state.

**3.1.1. Multivariate Shewhart Charts**

Multivariate Shewhart charts are fundamental tools in MSPC, primarily based on the Mahalanobis distance statistic.2 This statistic quantifies the distance of a data point from the process mean, taking into account the covariance structure between the variables. For monitoring the process mean, the Mahalanobis distance can be calculated using formulas that consider either known process parameters or parameters estimated from historical data.2 Under the assumption that the process variables follow a multivariate normal distribution, the Mahalanobis distance statistic follows a chi-square distribution, allowing for the determination of appropriate control limits.2 Multivariate Shewhart charts can also be used to monitor the process variance, typically by tracking the determinant or the trace of the covariance matrix.2 However, a noted limitation of these charts is their relative insensitivity to small and moderate shifts in the process mean, as they only utilize information from the current sample.2 This characteristic makes them more effective for detecting large, abrupt changes in the process rather than gradual drifts.

**3.1.2. Multivariate Cumulative Sum (MCUSUM) Charts**

To address the limitations of Shewhart charts in detecting smaller process shifts, Multivariate Cumulative Sum (MCUSUM) charts have been developed.2 MCUSUM charts work by accumulating deviations of the process from its target value over time. This cumulative approach enhances the sensitivity to small, sustained shifts that might not be immediately apparent on a Shewhart chart.2 MCUSUM schemes can be broadly classified into direction-specific schemes, which assume prior knowledge of the direction of the expected shift, and directionally invariant schemes, which do not make this assumption.2 Several specific MCUSUM techniques have been proposed in the literature, each with its own method for calculating the cumulative statistic and establishing control limits.2 By their nature of accumulating deviations, MCUSUM charts are particularly effective in detecting small to moderate, persistent changes in the process mean.

**3.1.3. Multivariate Exponentially Weighted Moving Average (MEWMA) Charts**

Similar to MCUSUM charts, Multivariate Exponentially Weighted Moving Average (MEWMA) charts are designed to be more sensitive to small to moderate shifts in the process mean compared to Shewhart charts.2 MEWMA charts calculate a weighted average of current and past observations, with weights that decrease exponentially over time, giving more emphasis to recent data.2 The multivariate EWMA control chart proposed by Lowry et al. is a well-known example.2 Like Shewhart charts, MEWMA charts are generally directionally invariant. The exponentially weighted moving average approach provides a smoothed representation of the process, making it effective for detecting gradual changes while being less susceptible to random noise than Shewhart charts.

**Numerical Example (Conceptual):**

Consider a process with two variables, temperature (T) and pressure (P), with target means of 50°C and 100 kPa, respectively.

* **Multivariate Shewhart Chart:** For a given sample, the Mahalanobis distance is calculated based on the deviation of the sample mean vector from the target mean vector and the process covariance matrix. If this distance exceeds a pre-determined control limit (based on the chi-square distribution), the process is considered out of control.  
* **MCUSUM Chart:** At each sampling point, a cumulative sum vector is calculated based on the deviation of the current observation from the target. The magnitude of this vector is then compared to a control limit. A sustained shift in either temperature or pressure would cause the cumulative sum to grow, eventually exceeding the limit.  
* **MEWMA Chart:** At each sampling point, a weighted average of the current and previous observations for both temperature and pressure is calculated. If this weighted average deviates significantly from the target mean vector (based on established control limits), it signals an out-of-control condition.

**3.2. Projection Methods**

Projection methods are powerful techniques used in MSPC to reduce the dimensionality of multivariate data while retaining the most important information. These methods are particularly useful for analyzing processes with a large number of correlated variables.

**3.2.1. Principal Component Analysis (PCA)**

Principal Component Analysis (PCA) is a foundational dimensionality reduction technique widely employed in MSPC benchmarking.2 PCA transforms a set of correlated variables into a smaller set of uncorrelated variables called principal components, which capture the maximum variance in the data.19 In the context of MSPC, PCA is often used to build a model of the normal operating conditions of a process. Once this model is established, new process data can be projected onto it, and deviations from the normal behavior can be detected using statistical metrics such as Hotelling's T² and Squared Prediction Error (SPE or Q).17 The T² statistic measures the distance of a new observation from the center of the normal data in the reduced dimensional space of the principal components, while the SPE statistic measures the lack of fit of the observation to the PCA model, indicating the amount of variation not captured by the principal components.17 Exceeding established control limits for either T² or SPE signals a potential fault or anomaly in the process.17

**Numerical Example:**

Consider a simplified process with two variables, X1 and X2. We collect data under normal operating conditions and perform PCA, retaining one principal component that explains most of the variance. The first principal component is a linear combination of X1 and X2. The normal operating data points cluster around a line in the original X1-X2 space, which corresponds to the direction of the first principal component. A new data point that falls far from this line in the X1-X2 space will have a high T² value (indicating its distance from the normal cluster along the principal component) and a high SPE value (indicating that it does not fit the PCA model well). Control limits for T² and SPE are established based on the distribution of these statistics for the normal operating data. If the T² or SPE value for the new data point exceeds these limits, it suggests that the process is operating abnormally.

**3.2.2. Multiway Principal Component Analysis (MPCA)**

Multiway Principal Component Analysis (MPCA) is an extension of PCA specifically designed to handle batch process data, which is typically structured as three-way arrays (batches x variables x time).1 MPCA involves a process called K-unfolding, where the three-way array is rearranged into a two-way matrix, allowing standard PCA to be applied.1 This method enables the monitoring of batch trajectories over time, capturing the evolution of multiple variables throughout the duration of each batch.1 By building an MPCA model on historical data from normal batch runs, future batches can be monitored for deviations from the expected profile, with T² and SPE statistics again serving as key indicators of abnormal behavior.1

**3.2.3. Partial Least Squares (PLS) and Multiway Partial Least Squares (MPLS)**

Partial Least Squares (PLS) is a projection method used to model the relationship between a set of process variables and a set of quality variables.1 It is particularly useful when there is a strong correlation between these two sets of variables, allowing for the prediction of quality parameters based on process measurements.1 Multiway Partial Least Squares (MPLS) extends PLS to handle batch process data in a similar manner to MPCA, involving K-unfolding of the data tensors.1 MPLS is valuable not only for monitoring process performance but also for predicting and controlling product quality in batch processes.1 Deviations in the process that might affect product quality can be detected by monitoring statistics derived from the MPLS model.

**Numerical Example (Conceptual):**

Imagine using PCA to monitor a chemical process with temperature and pressure measurements. Under normal conditions, these variables exhibit a certain correlation. A fault, such as a leak, might disrupt this correlation. When new data is projected onto the PCA model built from normal data, the T² statistic would increase, indicating a deviation from the normal relationship between temperature and pressure. Similarly, the SPE statistic might also increase if the fault introduces variation that was not present in the normal operating data used to train the model.

**4\. Key Evaluation Criteria and Performance Indicators in MSPC Benchmarking**

The performance of MSPC methods is typically evaluated using several key criteria and performance indicators that quantify their ability to effectively monitor processes and detect faults.25

**4.1. Detection Rate (True Positive Rate)**

The detection rate, also known as the true positive rate, represents the proportion of actual fault occurrences that are correctly identified by the MSPC method. A higher detection rate signifies better performance, indicating that the method is effective in identifying process anomalies when they occur.16

**4.2. False Alarm Rate (False Positive Rate)**

The false alarm rate, or false positive rate, is the proportion of normal operating conditions that are incorrectly flagged as faults by the MSPC method. A lower false alarm rate is desirable to minimize unnecessary process interventions and to maintain the trust of operators in the monitoring system.25

**4.3. Time to Detection**

The time to detection refers to the duration between the onset of a fault and its detection by the MSPC method. A shorter time to detection is crucial as it allows for quicker corrective actions to be taken, potentially reducing the impact of the fault on product quality and process efficiency.25

**4.4. Other Relevant Indicators**

In addition to detection rate, false alarm rate, and time to detection, other indicators are often considered in MSPC benchmarking. Sensitivity and specificity are closely related to detection and false alarm rates, respectively. Accuracy provides an overall measure of the correctness of fault classification, if the MSPC method includes diagnostic capabilities. Robustness assesses the performance of the method under the presence of noise or uncertainty in the data.18 Computational complexity is an important factor for real-time implementations, as it reflects the efficiency of the method. Finally, interpretability, the ease with which the cause of a detected fault can be identified 5, is highly valuable for effective process management and improvement. A comprehensive evaluation of MSPC methods necessitates considering a balance between these various performance indicators to ensure that the chosen method is well-suited for the specific application.25

**5\. Common Benchmarks Used in Production Lines for MSPC**

In real-world industrial production lines, MSPC techniques are increasingly being adopted to monitor complex processes and ensure product quality.1 These techniques find applications in diverse industries such as chemical processing, pharmaceuticals, and semiconductor manufacturing.1 The variables typically monitored in these settings include key process parameters like flow rates, pressures, and temperatures, as well as direct measurements of product quality.5 A common benchmarking practice involves establishing statistical control limits on these critical variables to define the boundaries of normal and acceptable process variation.21 These control limits are often derived from historical data collected during periods of stable operation. Deviations beyond these established limits trigger alarms, prompting investigations into the potential causes of the abnormality and enabling timely corrective actions to prevent defects and maintain process efficiency.30

The specific benchmarks employed can vary considerably depending on the industry and the particular process being monitored. For instance, a pharmaceutical production line, where stringent quality control is paramount, will likely have very tight control limits on critical parameters compared to a food processing plant. Similarly, the key quality attributes and process parameters that are monitored will differ based on the nature of the product and the manufacturing process.35 In many industrial applications, multivariate control charts, such as Shewhart, CUSUM, and EWMA charts, are utilized for real-time monitoring against these established benchmarks.2 Additionally, process capability indices like Cp and Cpk are often used to assess the inherent variability of a process relative to specified limits, serving as benchmarks for continuous improvement efforts.37

**6\. Comparative Studies and Performance Evaluation using Standardized Datasets**

Several research studies have leveraged standardized datasets like the Tennessee Eastman Process (TEP) to conduct comparative evaluations of different MSPC methods.5 These studies provide valuable insights into the relative strengths and weaknesses of various techniques under controlled conditions. For example, research has shown that Dynamic Principal Component Analysis with Decorrelated Residuals (DPCA-DR) exhibited superior fault detection rates on the TEP benchmark compared to traditional PCA and DPCA methods.16 Other work has compared the performance of Artificial Neural Networks (ANNs) trained using different software libraries on the TEP dataset, revealing variations in fault detection capabilities.46 Furthermore, the TEP dataset has been utilized as a benchmark for evaluating domain adaptation methods in the context of chemical processes.45 These comparative studies are crucial for both researchers and practitioners as they offer an objective basis for selecting the most appropriate MSPC techniques for specific applications and for identifying areas where further methodological advancements are needed. By evaluating methods on the same standardized data and using consistent performance metrics, the research community can make more informed decisions and accelerate progress in the field of multivariate statistical process control.

**7\. Conclusion and Recommendations**

The benchmarking of MSPC methods is essential for the advancement and practical application of these powerful process monitoring techniques. This report has highlighted the critical role of standardized datasets, such as the Tennessee Eastman Process (TEP), in providing a common platform for evaluating and comparing different MSPC methodologies. The TEP dataset, with its realistic simulation of an industrial chemical process and the inclusion of diverse fault scenarios, remains a cornerstone for benchmarking in this field. While other datasets like SECOM, ST-AWFD, and those related to specific equipment failures offer potential for targeted benchmarking, the TEP dataset's accessibility and comprehensive nature make it a valuable resource for a wide range of MSPC applications.

The primary methodologies employed for MSPC benchmarking include multivariate control charts (Shewhart, CUSUM, MEWMA) and projection methods (PCA, MPCA, PLS/MPLS). Each of these techniques has its own strengths and limitations in terms of sensitivity to different types of process shifts, ability to handle correlated variables, and suitability for batch versus continuous processes. The choice of method for benchmarking depends on the specific characteristics of the process under study and the types of faults or anomalies that are of primary concern.

Key evaluation criteria such as detection rate, false alarm rate, and time to detection are crucial for objectively assessing the performance of MSPC methods. Researchers and practitioners should strive for a balance between these indicators to select techniques that are both effective in identifying faults and reliable in minimizing unnecessary alarms.

For researchers, future efforts could focus on the development of more diverse and challenging standardized datasets that reflect the complexities of modern industrial processes, including issues like non-stationarity, data drift, and the presence of multiple interacting faults. Exploring novel benchmarking methodologies that go beyond traditional metrics and consider factors like interpretability and computational efficiency would also be beneficial. Practitioners should carefully consider the specific requirements of their processes when selecting standardized datasets and benchmarking methods. Utilizing the findings from comparative studies conducted on these datasets can provide valuable guidance in choosing the most appropriate MSPC techniques for their needs, ultimately leading to improved process monitoring, enhanced product quality, and increased operational efficiency.

#### **Referenzen**

1. (PDF) Multivariate statistical process control methods for batch ..., Zugriff am April 20, 2025, [https://www.researchgate.net/publication/348538563\_Multivariate\_statistical\_process\_control\_methods\_for\_batch\_production\_a\_review\_focused\_on\_applications](https://www.researchgate.net/publication/348538563_Multivariate_statistical_process_control_methods_for_batch_production_a_review_focused_on_applications)  
2. arxiv.org, Zugriff am April 20, 2025, [https://arxiv.org/pdf/0901.2880](https://arxiv.org/pdf/0901.2880)  
3. The EUPPBench postprocessing benchmark dataset v1.0 \- ESSD Copernicus, Zugriff am April 20, 2025, [https://essd.copernicus.org/articles/15/2635/2023/](https://essd.copernicus.org/articles/15/2635/2023/)  
4. TEP Dataset \- Kaggle, Zugriff am April 20, 2025, [https://www.kaggle.com/datasets/ma7bakr/tep-dataset/data](https://www.kaggle.com/datasets/ma7bakr/tep-dataset/data)  
5. The Tennessee Eastman Process: an Open Source Benchmark ..., Zugriff am April 20, 2025, [https://keepfloyding.github.io/posts/Ten-East-Proc-Intro/](https://keepfloyding.github.io/posts/Ten-East-Proc-Intro/)  
6. TEP Dataset \- Papers With Code, Zugriff am April 20, 2025, [https://paperswithcode.com/dataset/tep](https://paperswithcode.com/dataset/tep)  
7. Flow sheet of the Tennessee Eastman benchmark process ..., Zugriff am April 20, 2025, [https://www.researchgate.net/figure/Flow-sheet-of-the-Tennessee-Eastman-benchmark-process\_fig3\_275953276](https://www.researchgate.net/figure/Flow-sheet-of-the-Tennessee-Eastman-benchmark-process_fig3_275953276)  
8. Loading and Exploring the TEP Dataset \- KeepFloyding, Zugriff am April 20, 2025, [https://keepfloyding.github.io/posts/data-explor-TEP-1/](https://keepfloyding.github.io/posts/data-explor-TEP-1/)  
9. anasouzac/new\_tep\_datasets: New datasets for the ... \- GitHub, Zugriff am April 20, 2025, [https://github.com/anasouzac/new\_tep\_datasets](https://github.com/anasouzac/new_tep_datasets)  
10. Tennessee Eastman Process Dataset \- Papers With Code, Zugriff am April 20, 2025, [https://paperswithcode.com/dataset/tennessee-eastman-process](https://paperswithcode.com/dataset/tennessee-eastman-process)  
11. Tennessee Eastman Reference Data for Fault-Detection and ..., Zugriff am April 20, 2025, [https://data.dtu.dk/articles/dataset/Tennessee\_Eastman\_Reference\_Data\_for\_Fault-Detection\_and\_Decision\_Support\_Systems/13385936](https://data.dtu.dk/articles/dataset/Tennessee_Eastman_Reference_Data_for_Fault-Detection_and_Decision_Support_Systems/13385936)  
12. $$
2211.01645$$ Towards federated multivariate statistical process control (FedMSPC) \- arXiv, Zugriff am April 20, 2025, [https://arxiv.org/abs/2211.01645](https://arxiv.org/abs/2211.01645)  
13. Machine Learning Datasets \- Fault Detection \- Papers With Code, Zugriff am April 20, 2025, [https://paperswithcode.com/datasets?task=fault-detection\&lang=english\&page=1](https://paperswithcode.com/datasets?task=fault-detection&lang=english&page=1)  
14. STATISTICAL BATCH-BASED BEARING FAULT DETECTION \- arXiv, Zugriff am April 20, 2025, [https://arxiv.org/pdf/2407.17236](https://arxiv.org/pdf/2407.17236)  
15. Benchmark Datasets for Fault Detection and Classification in Sensor Data \- ResearchGate, Zugriff am April 20, 2025, [https://www.researchgate.net/publication/301721445\_Benchmark\_Datasets\_for\_Fault\_Detection\_and\_Classification\_in\_Sensor\_Data](https://www.researchgate.net/publication/301721445_Benchmark_Datasets_for_Fault_Detection_and_Classification_in_Sensor_Data)  
16. Fault detection in the Tennessee Eastman benchmark process using dynamic principal components analysis based on decorrelated res \- Estudo Geral, Zugriff am April 20, 2025, [https://estudogeral.uc.pt/bitstream/10316/27393/1/Fault%20detection%20in%20the%20Tennessee%20Eastman%20benchmark%20process.pdf](https://estudogeral.uc.pt/bitstream/10316/27393/1/Fault%20detection%20in%20the%20Tennessee%20Eastman%20benchmark%20process.pdf)  
17. A Holistic Evaluation of Multivariate Statistical Process Monitoring in ..., Zugriff am April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10928711/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10928711/)  
18. DEVELOPMENT AND BENCHMARKING OF MULTIVARIATE STATISTICAL PROCESS CONTROL TOOLS FOR A SEMICONDUCTOR ETCH PROCESS: IMPROVING ROBUS \- Eigenvector Research, Zugriff am April 20, 2025, [https://eigenvector.com/Docs/robustness.pdf](https://eigenvector.com/Docs/robustness.pdf)  
19. Fault Detection and Diagnosis using Multivariate Statistical Techniques in a Wastewater Treatment Plant. \*, Zugriff am April 20, 2025, [https://skoge.folk.ntnu.no/prost/proceedings/adchem09/cd/abstract/123.pdf](https://skoge.folk.ntnu.no/prost/proceedings/adchem09/cd/abstract/123.pdf)  
20. eigenvector.com, Zugriff am April 20, 2025, [https://eigenvector.com/Docs/Sensitivity.pdf](https://eigenvector.com/Docs/Sensitivity.pdf)  
21. Introduction to Multivariate SPC \- Einnosys, Zugriff am April 20, 2025, [https://www.einnosys.com/multivariate-spc/](https://www.einnosys.com/multivariate-spc/)  
22. Process Performance Monitoring Using Multivariate Statistical Process Control | Request PDF \- ResearchGate, Zugriff am April 20, 2025, [https://www.researchgate.net/publication/3351954\_Process\_Performance\_Monitoring\_Using\_Multivariate\_Statistical\_Process\_Control](https://www.researchgate.net/publication/3351954_Process_Performance_Monitoring_Using_Multivariate_Statistical_Process_Control)  
23. Multivariate SPC: Advanced Process Monitoring & Control Techniques \- SixSigma.us, Zugriff am April 20, 2025, [https://www.6sigma.us/six-sigma-in-focus/multivariate-spc/](https://www.6sigma.us/six-sigma-in-focus/multivariate-spc/)  
24. Full article: Multivariate statistical process control methods for batch ..., Zugriff am April 20, 2025, [https://www.tandfonline.com/doi/full/10.1080/21693277.2020.1871441](https://www.tandfonline.com/doi/full/10.1080/21693277.2020.1871441)  
25. On Reducing False Alarms in Multivariate Statistical Process Control \- CiteSeerX, Zugriff am April 20, 2025, [https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=7e0eb6d0a533ed6a9fb12d18c5fbb23d27088315](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7e0eb6d0a533ed6a9fb12d18c5fbb23d27088315)  
26. 30 MSP KPIs to Track & Measure Performance \- Thread, Zugriff am April 20, 2025, [https://www.getthread.com/blog/msp-kpis](https://www.getthread.com/blog/msp-kpis)  
27. 20 KPIs MSPs Should be Tracking \- ConnectWise, Zugriff am April 20, 2025, [https://www.connectwise.com/blog/profitability/msp-kpis](https://www.connectwise.com/blog/profitability/msp-kpis)  
28. Deep Convolutional Neural Network with Deconvolution and a Deep Autoencoder for Fault Detection and Diagnosis | ACS Omega \- ACS Publications, Zugriff am April 20, 2025, [https://pubs.acs.org/doi/10.1021/acsomega.1c06607](https://pubs.acs.org/doi/10.1021/acsomega.1c06607)  
29. Multivariate Statistical Process Monitoring \- PerceptiveAPC, Zugriff am April 20, 2025, [https://www.perceptiveapc.com/industries/pharmaceutical/solutions/spc\_mva/](https://www.perceptiveapc.com/industries/pharmaceutical/solutions/spc_mva/)  
30. Multivariate Statistical Process Control (MSPC) Technical Notes, Zugriff am April 20, 2025, [https://docs.tibco.com/pub/stat/14.0.0/doc/html/UsersGuide/GUID-06C2AE33-36E2-44B0-BB1A-5DB17153A9AA.html](https://docs.tibco.com/pub/stat/14.0.0/doc/html/UsersGuide/GUID-06C2AE33-36E2-44B0-BB1A-5DB17153A9AA.html)  
31. INDUSTRIAL CASE STUDY OF INNOVATIVE MANAGERIAL CONTROL SYSTEM APPLIED TO SITE CONTROL PROCESS (IMCS-CON) \- Anfas Thowfeek, Nashwan Dawood, Ramesh Marasini, John Dean, Zugriff am April 20, 2025, [https://itc.scix.net/pdfs/w78-2007-047-064-Thowfeek.pdf](https://itc.scix.net/pdfs/w78-2007-047-064-Thowfeek.pdf)  
32. MSPC For Process and Product Monitoring | PDF | Principal Component Analysis \- Scribd, Zugriff am April 20, 2025, [https://es.scribd.com/document/692140857/MSPC-for-Process-and-Product-monitoring](https://es.scribd.com/document/692140857/MSPC-for-Process-and-Product-monitoring)  
33. Screwing Process Monitoring Using MSPC in Large Scale Smart Manufacturing, Zugriff am April 20, 2025, [https://www.researchgate.net/publication/352462770\_Screwing\_Process\_Monitoring\_Using\_MSPC\_in\_Large\_Scale\_Smart\_Manufacturing](https://www.researchgate.net/publication/352462770_Screwing_Process_Monitoring_Using_MSPC_in_Large_Scale_Smart_Manufacturing)  
34. Multivariate Statistical Process Control: Process Monitoring Methods and Applications (Advances in Industrial Control) \- Amazon.com, Zugriff am April 20, 2025, [https://www.amazon.com/Multivariate-Statistical-Process-Control-Applications/dp/1447145127](https://www.amazon.com/Multivariate-Statistical-Process-Control-Applications/dp/1447145127)  
35. GUANinE v1.0: Benchmark Datasets for Genomic AI Sequence-to-Function Models \- PMC, Zugriff am April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10614795/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10614795/)  
36. What is Statistical Process Control? \- Design & Manufacturing \- Autodesk, Zugriff am April 20, 2025, [https://www.autodesk.com/blogs/design-and-manufacturing/2024/11/26/what-is-statistical-process-control/](https://www.autodesk.com/blogs/design-and-manufacturing/2024/11/26/what-is-statistical-process-control/)  
37. SPC \- Statistical Process Control: Manufacturing Explained \- Mingo Smart Factory, Zugriff am April 20, 2025, [https://www.mingosmartfactory.com/spc-statistical-process-control-manufacturing-explained/](https://www.mingosmartfactory.com/spc-statistical-process-control-manufacturing-explained/)  
38. Statistical Process Control (SPC) \- MoreSteam, Zugriff am April 20, 2025, [https://www.moresteam.com/toolbox/statistical-process-control](https://www.moresteam.com/toolbox/statistical-process-control)  
39. Statistical Process Control (SPC) Charts \- A World Class Tool \- AAMI, Zugriff am April 20, 2025, [https://www.aami.org/training/training-suites/quality-systems/statistical-process-control-spc-charts---a-world-class-tool](https://www.aami.org/training/training-suites/quality-systems/statistical-process-control-spc-charts---a-world-class-tool)  
40. Guide: Statistical Process Control (SPC) \- Learn Lean Sigma, Zugriff am April 20, 2025, [https://www.learnleansigma.com/guides/statistical-process-control-spc/](https://www.learnleansigma.com/guides/statistical-process-control-spc/)  
41. Statistical Process Control \- Benchmark Six Sigma, Zugriff am April 20, 2025, [https://www.benchmarksixsigma.com/corporate-programs/statistical-process-control/](https://www.benchmarksixsigma.com/corporate-programs/statistical-process-control/)  
42. STATISTICAL PROCESS CONTROL FOR TOTAL QUALITY \- Johns Hopkins University Applied Physics Laboratory, Zugriff am April 20, 2025, [https://www.jhuapl.edu/content/techdigest/pdf/V13-N02/13-02-Ali.pdf](https://www.jhuapl.edu/content/techdigest/pdf/V13-N02/13-02-Ali.pdf)  
43. Implementation of Statistical Process Control for Proteomic Experiments via LC MS/MS, Zugriff am April 20, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC4020592/](https://pmc.ncbi.nlm.nih.gov/articles/PMC4020592/)  
44. Fault detection in the Tennessee Eastman benchmark process using dynamic principal components analysis based on decorrelated residuals (DPCA-DR) | Request PDF \- ResearchGate, Zugriff am April 20, 2025, [https://www.researchgate.net/publication/257035406\_Fault\_detection\_in\_the\_Tennessee\_Eastman\_benchmark\_process\_using\_dynamic\_principal\_components\_analysis\_based\_on\_decorrelated\_residuals\_DPCA-DR](https://www.researchgate.net/publication/257035406_Fault_detection_in_the_Tennessee_Eastman_benchmark_process_using_dynamic_principal_components_analysis_based_on_decorrelated_residuals_DPCA-DR)  
45. $$
2308.11247$$ Benchmarking Domain Adaptation for Chemical Processes on the Tennessee Eastman Process \- arXiv, Zugriff am April 20, 2025, [https://arxiv.org/abs/2308.11247](https://arxiv.org/abs/2308.11247)  
46. A comparison study of basic data-driven fault diagnosis and process ..., Zugriff am April 20, 2025, [https://www.researchgate.net/publication/257407569\_A\_comparison\_study\_of\_basic\_data-driven\_fault\_diagnosis\_and\_process\_monitoring\_methods\_on\_the\_benchmark\_Tennessee\_Eastman\_process](https://www.researchgate.net/publication/257407569_A_comparison_study_of_basic_data-driven_fault_diagnosis_and_process_monitoring_methods_on_the_benchmark_Tennessee_Eastman_process)
